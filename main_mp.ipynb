{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d311d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is a modified version for implementing multiprocessing to speed up algorithm runs.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing # Added for multiprocessing\n",
    "import os # Added for path joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a97070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution import LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n",
    "from evolution import genetic_algorithm, hill_climbing, simulated_annealing\n",
    "from operators import (\n",
    "    mutate_swap_constrained,\n",
    "    mutate_targeted_player_exchange,\n",
    "    mutate_shuffle_within_team_constrained,\n",
    "    crossover_one_point_prefer_valid,\n",
    "    crossover_uniform_prefer_valid,\n",
    "    selection_ranking,\n",
    "    selection_tournament_variable_k,\n",
    "    selection_boltzmann\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c04d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load player data (remains global for now, passed to workers)\n",
    "players_df = pd.read_csv(\"players.csv\", sep=\";\")\n",
    "players_data_global = players_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3269a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define problem parameters (can be global or passed)\n",
    "NUM_TEAMS_GLOBAL = 5\n",
    "TEAM_SIZE_GLOBAL = 7\n",
    "MAX_BUDGET_GLOBAL = 750\n",
    "NUM_RUNS_GLOBAL = 30 # Default, will be used by the main part of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f8322",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Worker function for Hill Climbing ---\n",
    "def hc_worker(args_tuple):\n",
    "    run_id, p_data, n_teams, t_size, m_budget, max_iter, verbose_flag = args_tuple\n",
    "    start_time_hc_run = time.time()\n",
    "    initial_hc_solution_run = LeagueHillClimbingSolution(p_data, num_teams=n_teams, team_size=t_size, max_budget=m_budget)\n",
    "    retry_attempts_hc = 0\n",
    "    max_retry_hc = 5\n",
    "    while not initial_hc_solution_run.is_valid(p_data) and retry_attempts_hc < max_retry_hc:\n",
    "        initial_hc_solution_run = LeagueHillClimbingSolution(p_data, num_teams=n_teams, team_size=t_size, max_budget=m_budget)\n",
    "        retry_attempts_hc += 1\n",
    "    if not initial_hc_solution_run.is_valid(p_data):\n",
    "        return {\"run_id\": run_id, \"fitness\": float('nan'), \"exec_time\": time.time() - start_time_hc_run, \"solution_assignment\": None, \"history\": []}\n",
    "    hc_solution_obj_run, hc_fitness_val_run, hc_history_convergence_run = hill_climbing(\n",
    "        initial_solution=initial_hc_solution_run, \n",
    "        players_data=p_data, \n",
    "        max_iterations=max_iter, \n",
    "        verbose=verbose_flag\n",
    "    )\n",
    "    end_time_hc_run = time.time()\n",
    "    hc_exec_time_run = end_time_hc_run - start_time_hc_run\n",
    "    if hc_solution_obj_run:\n",
    "        return {\"run_id\": run_id, \"fitness\": hc_fitness_val_run, \"exec_time\": hc_exec_time_run, \"solution_assignment\": hc_solution_obj_run.assignment, \"history\": hc_history_convergence_run}\n",
    "    else:\n",
    "        return {\"run_id\": run_id, \"fitness\": float('nan'), \"exec_time\": hc_exec_time_run, \"solution_assignment\": None, \"history\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d58e5e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Worker function for Simulated Annealing ---\n",
    "def sa_worker(args_tuple):\n",
    "    run_id, p_data, n_teams, t_size, m_budget, sa_params_dict, verbose_flag = args_tuple\n",
    "    start_time_sa_run = time.time()\n",
    "    initial_sa_solution = LeagueSASolution(p_data, num_teams=n_teams, team_size=t_size, max_budget=m_budget)\n",
    "    retry_attempts_sa = 0\n",
    "    max_retry_sa = 5\n",
    "    while not initial_sa_solution.is_valid(p_data) and retry_attempts_sa < max_retry_sa:\n",
    "        initial_sa_solution = LeagueSASolution(p_data, num_teams=n_teams, team_size=t_size, max_budget=m_budget)\n",
    "        retry_attempts_sa += 1\n",
    "    if not initial_sa_solution.is_valid(p_data):\n",
    "        return {\"run_id\": run_id, \"fitness\": float('nan'), \"exec_time\": time.time() - start_time_sa_run, \"solution_assignment\": None, \"history\": []}\n",
    "    sa_solution_run, sa_fitness_run, sa_history_run = simulated_annealing(\n",
    "        initial_solution=initial_sa_solution,\n",
    "        players_data=p_data,\n",
    "        initial_temp=sa_params_dict[\"initial_temp\"],\n",
    "        final_temp=sa_params_dict[\"final_temp\"],\n",
    "        alpha=sa_params_dict[\"alpha\"],\n",
    "        iterations_per_temp=sa_params_dict[\"iterations_per_temp\"],\n",
    "        verbose=verbose_flag\n",
    "    )\n",
    "    end_time_sa_run = time.time()\n",
    "    sa_exec_time_run = end_time_sa_run - start_time_sa_run\n",
    "    if sa_solution_run:\n",
    "        return {\"run_id\": run_id, \"fitness\": sa_fitness_run, \"exec_time\": sa_exec_time_run, \"solution_assignment\": sa_solution_run.assignment, \"history\": sa_history_run}\n",
    "    else:\n",
    "        return {\"run_id\": run_id, \"fitness\": float('nan'), \"exec_time\": sa_exec_time_run, \"solution_assignment\": None, \"history\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9721174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Worker function for Genetic Algorithm ---\n",
    "def ga_worker(args_tuple):\n",
    "    run_id, p_data, n_teams, t_size, m_budget, ga_config_dict, ga_params_dict, verbose_flag = args_tuple\n",
    "    start_time_ga_run = time.time()\n",
    "    best_solution_ga_run, history_ga_run = genetic_algorithm(\n",
    "        players_data=p_data,\n",
    "        num_teams=n_teams,\n",
    "        team_size=t_size,\n",
    "        max_budget=m_budget,\n",
    "        population_size=ga_params_dict[\"population_size\"],\n",
    "        generations=ga_params_dict[\"generations\"],\n",
    "        mutation_rate=ga_params_dict[\"mutation_rate\"],\n",
    "        elite_size=ga_params_dict[\"elitism_size\"], \n",
    "        mutation_operator_func=ga_config_dict[\"mutation_operator_func\"],\n",
    "        crossover_operator_func=ga_config_dict[\"crossover_operator_func\"],\n",
    "        selection_operator_func=ga_config_dict[\"selection_operator_func\"],\n",
    "        tournament_k=ga_config_dict.get(\"tournament_k\"),\n",
    "        boltzmann_temp=ga_config_dict.get(\"boltzmann_temp\"),\n",
    "        verbose=verbose_flag\n",
    "    )\n",
    "    end_time_ga_run = time.time()\n",
    "    ga_exec_time_run = end_time_ga_run - start_time_ga_run\n",
    "\n",
    "    if best_solution_ga_run:\n",
    "        best_fitness_ga_run = best_solution_ga_run.fitness(p_data) \n",
    "        return {\"run_id\": run_id, \"fitness\": best_fitness_ga_run, \"exec_time\": ga_exec_time_run, \"solution_assignment\": best_solution_ga_run.assignment, \"history\": history_ga_run, \"config_name\": ga_config_dict[\"name\"]}\n",
    "    else:\n",
    "        return {\"run_id\": run_id, \"fitness\": float('nan'), \"exec_time\": ga_exec_time_run, \"solution_assignment\": None, \"history\": [], \"config_name\": ga_config_dict[\"name\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380543de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    script_start_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Multi-Processor Script execution started.\")\n",
    "\n",
    "    MP_GRAPHS_DIR = \"/home/ubuntu/CIFO_EXTENDED_Project/mp_graphs\"\n",
    "    if not os.path.exists(MP_GRAPHS_DIR):\n",
    "        os.makedirs(MP_GRAPHS_DIR)\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Created directory: {MP_GRAPHS_DIR}\")\n",
    "\n",
    "    try:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    except NotImplementedError:\n",
    "        num_processes = 4 \n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Using {num_processes} processes for parallel execution.\")\n",
    "\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Loading player data...\")\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Player data loaded successfully. Total players: {len(players_data_global)}\")\n",
    "    if players_data_global:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] First player data: {players_data_global[0]}\")\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] All algorithms (HC, SA, GA) will be run {NUM_RUNS_GLOBAL} times each using multiprocessing.\")\n",
    "\n",
    "    all_results_summary = []\n",
    "\n",
    "    # ---- 1. Hill Climbing ----\n",
    "    hc_section_start_time = time.time()\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Hill Climbing Algorithm ({NUM_RUNS_GLOBAL} runs) ---\")\n",
    "    hc_args_list = []\n",
    "    for i in range(NUM_RUNS_GLOBAL):\n",
    "        hc_args_list.append((i, players_data_global, NUM_TEAMS_GLOBAL, TEAM_SIZE_GLOBAL, MAX_BUDGET_GLOBAL, 1000, False))\n",
    "    \n",
    "    hc_results_parallel = []\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Launching Hill Climbing worker pool...\")\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        hc_results_parallel = pool.map(hc_worker, hc_args_list)\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing worker pool finished.\")\n",
    "\n",
    "    hc_all_fitness_values = [res[\"fitness\"] for res in hc_results_parallel]\n",
    "    hc_all_exec_times = [res[\"exec_time\"] for res in hc_results_parallel]\n",
    "    best_hc_fitness_overall = float(\"inf\")\n",
    "    best_hc_solution_assignment_overall = None\n",
    "    best_hc_history_overall = []\n",
    "\n",
    "    for res in hc_results_parallel:\n",
    "        if res[\"solution_assignment\"] is not None and not np.isnan(res[\"fitness\"]) and res[\"fitness\"] < best_hc_fitness_overall:\n",
    "            best_hc_fitness_overall = res[\"fitness\"]\n",
    "            best_hc_solution_assignment_overall = res[\"solution_assignment\"]\n",
    "            best_hc_history_overall = res[\"history\"]\n",
    "\n",
    "    hc_mean_fitness = np.nanmean(hc_all_fitness_values) if hc_all_fitness_values else float(\"nan\")\n",
    "    hc_std_fitness = np.nanstd(hc_all_fitness_values) if hc_all_fitness_values else float(\"nan\")\n",
    "    hc_mean_exec_time_per_run = np.nanmean(hc_all_exec_times) if hc_all_exec_times else float(\"nan\")\n",
    "    hc_section_end_time = time.time()\n",
    "\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing ({NUM_RUNS_GLOBAL} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {hc_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {hc_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {hc_mean_exec_time_per_run:.2f}s\")\n",
    "    if best_hc_solution_assignment_overall is not None:\n",
    "        print(f\"  Overall Best HC Fitness: {best_hc_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": \"Hill Climbing (MP)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time_per_run,\n",
    "            \"Overall Best Fitness\": best_hc_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(best_hc_history_overall, marker=\"o\", linestyle=\"-\")\n",
    "        plt.title(f\"Hill Climbing Convergence (Best of {NUM_RUNS_GLOBAL} Runs - MP)\")\n",
    "        plt.xlabel(\"Improvement Step\")\n",
    "        plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(MP_GRAPHS_DIR, \"hc_convergence_mp.png\"))\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved Hill Climbing convergence plot to {MP_GRAPHS_DIR}/hc_convergence_mp.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": \"Hill Climbing (MP)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time_per_run,\n",
    "            \"Overall Best Fitness\": float('nan'),\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing section took {hc_section_end_time - hc_section_start_time:.2f} seconds.\")\n",
    "\n",
    "    # ---- 2. Simulated Annealing ----\n",
    "    sa_section_start_time = time.time()\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Simulated Annealing Algorithm ({NUM_RUNS_GLOBAL} runs) ---\")\n",
    "    sa_params_dict = {\n",
    "        \"initial_temp\": 1000,\n",
    "        \"final_temp\": 0.1,\n",
    "        \"alpha\": 0.99,\n",
    "        \"iterations_per_temp\": 50\n",
    "    }\n",
    "    sa_args_list = []\n",
    "    for i in range(NUM_RUNS_GLOBAL):\n",
    "        sa_args_list.append((i, players_data_global, NUM_TEAMS_GLOBAL, TEAM_SIZE_GLOBAL, MAX_BUDGET_GLOBAL, sa_params_dict, False))\n",
    "\n",
    "    sa_results_parallel = []\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Launching Simulated Annealing worker pool...\")\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        sa_results_parallel = pool.map(sa_worker, sa_args_list)\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing worker pool finished.\")\n",
    "\n",
    "    sa_all_fitness_values = [res[\"fitness\"] for res in sa_results_parallel]\n",
    "    sa_all_exec_times = [res[\"exec_time\"] for res in sa_results_parallel]\n",
    "    best_sa_fitness_overall = float(\"inf\")\n",
    "    best_sa_solution_assignment_overall = None\n",
    "    best_sa_history_overall = []\n",
    "\n",
    "    for res in sa_results_parallel:\n",
    "        if res[\"solution_assignment\"] is not None and not np.isnan(res[\"fitness\"]) and res[\"fitness\"] < best_sa_fitness_overall:\n",
    "            best_sa_fitness_overall = res[\"fitness\"]\n",
    "            best_sa_solution_assignment_overall = res[\"solution_assignment\"]\n",
    "            best_sa_history_overall = res[\"history\"]\n",
    "    \n",
    "    sa_mean_fitness = np.nanmean(sa_all_fitness_values) if sa_all_fitness_values else float(\"nan\")\n",
    "    sa_std_fitness = np.nanstd(sa_all_fitness_values) if sa_all_fitness_values else float(\"nan\")\n",
    "    sa_mean_exec_time_per_run = np.nanmean(sa_all_exec_times) if sa_all_exec_times else float(\"nan\")\n",
    "    sa_section_end_time = time.time()\n",
    "\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing ({NUM_RUNS_GLOBAL} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {sa_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {sa_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {sa_mean_exec_time_per_run:.2f}s\")\n",
    "    if best_sa_solution_assignment_overall is not None:\n",
    "        print(f\"  Overall Best SA Fitness: {best_sa_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": \"Simulated Annealing (MP)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time_per_run,\n",
    "            \"Overall Best Fitness\": best_sa_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(best_sa_history_overall, linestyle=\"-\")\n",
    "        plt.title(f\"Simulated Annealing Convergence (Best of {NUM_RUNS_GLOBAL} Runs - MP)\")\n",
    "        plt.xlabel(\"Iteration Step\")\n",
    "        plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(MP_GRAPHS_DIR, \"sa_convergence_mp.png\"))\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved Simulated Annealing convergence plot to {MP_GRAPHS_DIR}/sa_convergence_mp.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": \"Simulated Annealing (MP)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time_per_run,\n",
    "            \"Overall Best Fitness\": float('nan'),\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing section took {sa_section_end_time - sa_section_start_time:.2f} seconds.\")\n",
    "\n",
    "    # ---- 3. Genetic Algorithms ----\n",
    "    ga_section_start_time = time.time()\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Genetic Algorithms ({NUM_RUNS_GLOBAL} runs per config) ---\")\n",
    "    ga_params_dict = {\n",
    "        \"population_size\": 50,\n",
    "        \"generations\": 100,\n",
    "        \"mutation_rate\": 0.1,\n",
    "        \"crossover_rate\": 0.8, \n",
    "        \"elitism_size\": 2 \n",
    "    }\n",
    "    ga_configs_new = [\n",
    "        {\n",
    "            \"name\": \"GA_Config_1 (SwapConst,1PtPreferV,TournVarK)\",\n",
    "            \"mutation_operator_func\": mutate_swap_constrained,\n",
    "            \"crossover_operator_func\": crossover_one_point_prefer_valid,\n",
    "            \"selection_operator_func\": selection_tournament_variable_k,\n",
    "            \"tournament_k\": 3,\n",
    "            \"boltzmann_temp\": None \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GA_Config_2 (TargetExch,UnifPreferV,Ranking)\",\n",
    "            \"mutation_operator_func\": mutate_targeted_player_exchange,\n",
    "            \"crossover_operator_func\": crossover_uniform_prefer_valid,\n",
    "            \"selection_operator_func\": selection_ranking,\n",
    "            \"tournament_k\": None, \n",
    "            \"boltzmann_temp\": None \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GA_Config_3 (ShuffleWithin,1PtPreferV,Boltzmann)\",\n",
    "            \"mutation_operator_func\": mutate_shuffle_within_team_constrained,\n",
    "            \"crossover_operator_func\": crossover_one_point_prefer_valid,\n",
    "            \"selection_operator_func\": selection_boltzmann,\n",
    "            \"tournament_k\": None, \n",
    "            \"boltzmann_temp\": 50 \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GA_Config_4 (TargetExch,UnifPreferV,TournVarK_k5)\",\n",
    "            \"mutation_operator_func\": mutate_targeted_player_exchange,\n",
    "            \"crossover_operator_func\": crossover_uniform_prefer_valid,\n",
    "            \"selection_operator_func\": selection_tournament_variable_k,\n",
    "            \"tournament_k\": 5, \n",
    "            \"boltzmann_temp\": None \n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for ga_config in ga_configs_new:\n",
    "        ga_config_start_time_inner = time.time()\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] Running GA Configuration: {ga_config['name']}\")\n",
    "        ga_args_list_config = []\n",
    "        for i in range(NUM_RUNS_GLOBAL):\n",
    "            ga_args_list_config.append((i, players_data_global, NUM_TEAMS_GLOBAL, TEAM_SIZE_GLOBAL, MAX_BUDGET_GLOBAL, ga_config, ga_params_dict, False))\n",
    "\n",
    "        ga_results_parallel_config = []\n",
    "        print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] Launching GA worker pool for {ga_config['name']}...\")\n",
    "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "            ga_results_parallel_config = pool.map(ga_worker, ga_args_list_config)\n",
    "        print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA worker pool for {ga_config['name']} finished.\")\n",
    "\n",
    "        ga_all_fitness_values_config = [res[\"fitness\"] for res in ga_results_parallel_config]\n",
    "        ga_all_exec_times_config = [res[\"exec_time\"] for res in ga_results_parallel_config]\n",
    "        best_ga_fitness_config = float(\"inf\")\n",
    "        best_ga_solution_assignment_config = None\n",
    "        best_ga_history_config = []\n",
    "\n",
    "        for res in ga_results_parallel_config:\n",
    "            if res[\"solution_assignment\"] is not None and not np.isnan(res[\"fitness\"]) and res[\"fitness\"] < best_ga_fitness_config:\n",
    "                best_ga_fitness_config = res[\"fitness\"]\n",
    "                best_ga_solution_assignment_config = res[\"solution_assignment\"]\n",
    "                best_ga_history_config = res[\"history\"]\n",
    "\n",
    "        ga_mean_fitness_config = np.nanmean(ga_all_fitness_values_config) if ga_all_fitness_values_config else float(\"nan\")\n",
    "        ga_std_fitness_config = np.nanstd(ga_all_fitness_values_config) if ga_all_fitness_values_config else float(\"nan\")\n",
    "        ga_mean_exec_time_config = np.nanmean(ga_all_exec_times_config) if ga_all_exec_times_config else float(\"nan\")\n",
    "\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA Config {ga_config['name']} ({NUM_RUNS_GLOBAL} runs) processing finished.\")\n",
    "        print(f\"    Mean Best Fitness: {ga_mean_fitness_config:.4f}\")\n",
    "        print(f\"    Std Dev Best Fitness: {ga_std_fitness_config:.4f}\")\n",
    "        print(f\"    Mean Execution Time per run: {ga_mean_exec_time_config:.2f}s\")\n",
    "        if best_ga_solution_assignment_config is not None:\n",
    "            print(f\"    Overall Best GA Fitness for Config: {best_ga_fitness_config:.4f}\")\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": ga_config['name'] + \" (MP)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": best_ga_fitness_config,\n",
    "                \"Mutation Op\": ga_config[\"mutation_operator_func\"].__name__,\n",
    "                \"Crossover Op\": ga_config[\"crossover_operator_func\"].__name__,\n",
    "                \"Selection Op\": ga_config[\"selection_operator_func\"].__name__\n",
    "            })\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_ga_history_config, linestyle=\"-\")\n",
    "            plt.title(f\"GA Convergence ({ga_config['name']} - Best of {NUM_RUNS_GLOBAL} Runs - MP)\")\n",
    "            plt.xlabel(\"Generation\")\n",
    "            plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "            plt.grid(True)\n",
    "            sanitized_config_name = ga_config['name'].replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")\n",
    "            plt.savefig(os.path.join(MP_GRAPHS_DIR, f\"ga_convergence_{sanitized_config_name}_mp.png\"))\n",
    "            print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved GA convergence plot to {MP_GRAPHS_DIR}/ga_convergence_{sanitized_config_name}_mp.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA Config {ga_config['name']} did not find any valid solution across all runs that produced a best overall.\")\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": ga_config['name'] + \" (MP)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": float('nan'),\n",
    "                \"Mutation Op\": ga_config[\"mutation_operator_func\"].__name__,\n",
    "                \"Crossover Op\": ga_config[\"crossover_operator_func\"].__name__,\n",
    "                \"Selection Op\": ga_config[\"selection_operator_func\"].__name__\n",
    "            })\n",
    "        ga_config_end_time_inner = time.time()\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA Configuration {ga_config['name']} took {ga_config_end_time_inner - ga_config_start_time_inner:.2f} seconds.\")\n",
    "    ga_section_end_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Genetic Algorithms section took {ga_section_end_time - ga_section_start_time:.2f} seconds.\")\n",
    "\n",
    "    # ---- 4. Comparative Analysis ----\n",
    "    analysis_start_time = time.time()\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Comparative Analysis ---\")\n",
    "    results_df = pd.DataFrame(all_results_summary)\n",
    "    print(\"Results Summary Table (MP):\")\n",
    "    print(results_df.to_string())\n",
    "\n",
    "    # Plotting comparative fitness\n",
    "    plt.figure(figsize=(14, 8)) \n",
    "    results_df_sorted_fitness = results_df.sort_values(by=\"Mean Fitness\")\n",
    "    plt.bar(results_df_sorted_fitness[\"Algorithm\"], results_df_sorted_fitness[\"Mean Fitness\"], yerr=results_df_sorted_fitness[\"Std Dev Fitness\"], capsize=5, color=\"skyblue\")\n",
    "    plt.xlabel(\"Algorithm Configuration\")\n",
    "    plt.ylabel(\"Mean Best Fitness (Lower is Better)\")\n",
    "    plt.title(\"Comparative Mean Best Fitness of Algorithms (MP)\")\n",
    "    plt.xticks(rotation=60, ha=\"right\") \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MP_GRAPHS_DIR, \"comparative_fitness_mp.png\"))\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved comparative fitness plot to {MP_GRAPHS_DIR}/comparative_fitness_mp.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plotting comparative execution times\n",
    "    plt.figure(figsize=(14, 8)) \n",
    "    results_df_sorted_time = results_df.sort_values(by=\"Mean Exec Time (s)\")\n",
    "    plt.bar(results_df_sorted_time[\"Algorithm\"], results_df_sorted_time[\"Mean Exec Time (s)\"], color=\"lightcoral\")\n",
    "    plt.xlabel(\"Algorithm Configuration\")\n",
    "    plt.ylabel(\"Mean Execution Time (s)\")\n",
    "    plt.title(\"Comparative Mean Execution Times of Algorithms (MP)\")\n",
    "    plt.xticks(rotation=60, ha=\"right\") \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MP_GRAPHS_DIR, \"comparative_times_mp.png\"))\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved comparative execution times plot to {MP_GRAPHS_DIR}/comparative_times_mp.png\")\n",
    "    plt.close()\n",
    "    analysis_end_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Comparative Analysis section took {analysis_end_time - analysis_start_time:.2f} seconds.\")\n",
    "\n",
    "    script_end_time = time.time()\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] Multi-Processor Script finished. Total execution time: {script_end_time - script_start_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
