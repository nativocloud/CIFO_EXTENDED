{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed2dd5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b0b1d7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This work presents a constrained combinatorial optimization approach to the **Sports League Assignment Problem** using **Genetic Algorithms (GAs)**, **Hill Climbing (HC)**, and **Simulated Annealing (SA)**. The objective is to allocate a fixed pool of professional players into a set of 5 structurally valid teams in such a way that the **standard deviation of the teams\\\" average skill ratings** is minimized—promoting competitive balance across the league.\n",
    "\n",
    "Each player is defined by three attributes: **position** (one of `GK`, `DEF`, `MID`, `FWD`), **skill rating** (a numerical measure of ability), and **cost** (in million euros). A valid solution must satisfy the following **hard constraints**:\n",
    "\n",
    "- Each team must consist of exactly **7 players**, with a specific positional structure: **1 GK, 2 DEF, 2 MID, and 2 FWD**\n",
    "- Each team must have a **total cost ≤ 750 million €**\n",
    "- Each player must be assigned to **exactly one team** (no overlaps)\n",
    "\n",
    "The **search space** is therefore highly constrained and discrete, and infeasible configurations are explicitly excluded from the solution space. The optimization objective is to identify league configurations where teams are not only valid but also **skill-balanced**, quantified by the **standard deviation of average skill ratings across teams**, which serves as the **fitness function** (to be minimized).\n",
    "\n",
    "This script adapts the single-processor version to utilize **multiprocessing** to run multiple independent trials of each algorithm concurrently, allowing for more robust statistical analysis of their performance within a shorter timeframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54c333",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Critical Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os # Added for path joining\n",
    "import multiprocessing # Added for multiprocessing\n",
    "# cProfile and pstats are generally for single-process profiling, might be complex with multiprocessing\n",
    "# For now, we focus on timing the parallel runs themselves.\n",
    "\n",
    "from solution import LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n",
    "from evolution import genetic_algorithm, hill_climbing, simulated_annealing \n",
    "from operators import (\n",
    "    # Base Mutations\n",
    "    mutate_swap,\n",
    "    mutate_team_shift,\n",
    "    mutate_shuffle_team,\n",
    "    # New/Adapted Mutations\n",
    "    mutate_swap_constrained,\n",
    "    mutate_targeted_player_exchange,\n",
    "    mutate_shuffle_within_team_constrained,\n",
    "    # Base Crossovers\n",
    "    crossover_one_point,\n",
    "    crossover_uniform,\n",
    "    # New/Adapted Crossovers\n",
    "    crossover_one_point_prefer_valid,\n",
    "    crossover_uniform_prefer_valid,\n",
    "    # Selection Operators\n",
    "    selection_ranking,\n",
    "    selection_tournament_variable_k,\n",
    "    selection_boltzmann\n",
    ")\n",
    "\n",
    "# Define number of runs for stochastic algorithms\n",
    "NUM_RUNS = 1 # Parameter for number of runs (e.g., 1, 5, 10, 30) - SET FOR CURRENT TEST\n",
    "\n",
    "# Define the directory for saving graphs and results\n",
    "MULTIPROCESSING_RESULTS_DIR = f\"/home/ubuntu/CIFO_EXTENDED_Project/images_mp/run_{NUM_RUNS}_results\" # Dynamic based on NUM_RUNS\n",
    "IMAGES_MP_DIR = MULTIPROCESSING_RESULTS_DIR\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(IMAGES_MP_DIR):\n",
    "    os.makedirs(IMAGES_MP_DIR)\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Created directory: {IMAGES_MP_DIR}\")\n",
    "\n",
    "# Load player data (globally for worker processes to access if needed, though it's better to pass it)\n",
    "players_df = pd.read_csv(\"players.csv\", sep=\";\")\n",
    "PLAYERS_DATA_GLOBAL = players_df.to_dict(orient=\"records\") # Renamed for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeee0a9",
   "metadata": {},
   "source": [
    "## Cell 2: Further Setup, Data Inspection, and Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241c4ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define problem parameters\n",
    "NUM_TEAMS = 5\n",
    "TEAM_SIZE = 7\n",
    "MAX_BUDGET = 750\n",
    "\n",
    "# Define number of runs for stochastic algorithms\n",
    "NUM_RUNS = 1 # Parameter for number of runs (e.g., 5, 10, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2152e",
   "metadata": {},
   "source": [
    "## Helper Functions for Multiprocessing Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hill_climbing_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, max_iterations_hc):\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] HC Run {run_id+1}/{NUM_RUNS} starting...\")\n",
    "    start_time_hc_run = time.time()\n",
    "    \n",
    "    initial_hc_solution_run = LeagueHillClimbingSolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "    retry_attempts_hc = 0\n",
    "    max_retry_hc = 5\n",
    "    while not initial_hc_solution_run.is_valid() and retry_attempts_hc < max_retry_hc:\n",
    "        initial_hc_solution_run = LeagueHillClimbingSolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "        retry_attempts_hc += 1\n",
    "    \n",
    "    if not initial_hc_solution_run.is_valid():\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  [{timestamp}] HC Run {run_id+1} failed to create a valid initial solution after {max_retry_hc} retries. Skipping run.\")\n",
    "        return None, float(\"nan\"), float(\"nan\"), []\n",
    "\n",
    "    hc_solution_obj_run, hc_fitness_val_run, hc_history_convergence_run = hill_climbing(\n",
    "        initial_solution=initial_hc_solution_run, \n",
    "        players_data=players_data_local, \n",
    "        max_iterations=max_iterations_hc, \n",
    "        verbose=False\n",
    "    )\n",
    "    end_time_hc_run = time.time()\n",
    "    hc_exec_time_run = end_time_hc_run - start_time_hc_run\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] HC Run {run_id+1} finished in {hc_exec_time_run:.2f}s with fitness {hc_fitness_val_run if hc_solution_obj_run else 'N/A'}.\")\n",
    "    return hc_solution_obj_run, hc_fitness_val_run if hc_solution_obj_run else float(\"nan\"), hc_exec_time_run, hc_history_convergence_run\n",
    "\n",
    "def run_simulated_annealing_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, sa_params_local):\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] SA Run {run_id+1}/{NUM_RUNS} starting...\")\n",
    "    start_time_sa_run = time.time()\n",
    "    initial_sa_solution = LeagueSASolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "    retry_attempts_sa = 0\n",
    "    max_retry_sa = 5\n",
    "    while not initial_sa_solution.is_valid() and retry_attempts_sa < max_retry_sa:\n",
    "        initial_sa_solution = LeagueSASolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "        retry_attempts_sa += 1\n",
    "\n",
    "    if not initial_sa_solution.is_valid():\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  [{timestamp}] SA Run {run_id+1} failed to create a valid initial solution after {max_retry_sa} retries. Skipping run.\")\n",
    "        return None, float(\"nan\"), float(\"nan\"), []\n",
    "\n",
    "    sa_solution_run, sa_fitness_run, sa_history_run = simulated_annealing(\n",
    "        initial_solution=initial_sa_solution,\n",
    "        players_data=players_data_local, \n",
    "        initial_temp=sa_params_local[\"initial_temp\"],\n",
    "        final_temp=sa_params_local[\"final_temp\"],\n",
    "        alpha=sa_params_local[\"alpha\"],\n",
    "        iterations_per_temp=sa_params_local[\"iterations_per_temp\"],\n",
    "        verbose=False\n",
    "    )\n",
    "    end_time_sa_run = time.time()\n",
    "    sa_exec_time_run = end_time_sa_run - start_time_sa_run\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] SA Run {run_id+1} finished in {sa_exec_time_run:.2f}s with fitness {sa_fitness_run if sa_solution_run else 'N/A'}.\")\n",
    "    return sa_solution_run, sa_fitness_run if sa_solution_run else float(\"nan\"), sa_exec_time_run, sa_history_run\n",
    "\n",
    "def run_genetic_algorithm_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, ga_params_local, config_name_local):\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] GA Run {run_id+1}/{NUM_RUNS} for {config_name_local} starting...\")\n",
    "    start_time_ga_run = time.time()\n",
    "    \n",
    "    best_solution_ga_run, fitness_history_ga_run = genetic_algorithm(\n",
    "        players_data=players_data_local, \n",
    "        population_size=ga_params_local[\"population_size\"],\n",
    "        generations=ga_params_local[\"generations\"],\n",
    "        mutation_rate=ga_params_local[\"mutation_rate\"],\n",
    "        elite_size=ga_params_local[\"elitism_size\"],\n",
    "        mutation_operator_func=ga_params_local[\"mutation_op\"], \n",
    "        crossover_operator_func=ga_params_local[\"crossover_op\"],\n",
    "        selection_operator_func=ga_params_local[\"selection_op\"],\n",
    "        tournament_k=ga_params_local.get(\"tournament_k\", 3),\n",
    "        boltzmann_temp=ga_params_local.get(\"boltzmann_temp\", 100),\n",
    "        num_teams=num_teams_local, \n",
    "        team_size=team_size_local,\n",
    "        max_budget=max_budget_local,\n",
    "        verbose=False \n",
    "    )\n",
    "    \n",
    "    end_time_ga_run = time.time()\n",
    "    actual_exec_time_ga_run = end_time_ga_run - start_time_ga_run \n",
    "    best_fitness_ga_run = best_solution_ga_run.fitness() if best_solution_ga_run else float(\"nan\")\n",
    "    \n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"  [{timestamp}] GA Run {run_id+1} for {config_name_local} finished in {actual_exec_time_ga_run:.2f}s with fitness {best_fitness_ga_run if best_solution_ga_run else 'N/A'}.\")\n",
    "    return best_solution_ga_run, best_fitness_ga_run, actual_exec_time_ga_run, fitness_history_ga_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf2497",
   "metadata": {},
   "source": [
    "## Main Execution Block (Adapted for Multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    script_total_start_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Multiprocessing Script for {NUM_RUNS} runs execution started.\")\n",
    "\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Player data loaded. Total players: {len(PLAYERS_DATA_GLOBAL)}\")\n",
    "    if PLAYERS_DATA_GLOBAL:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] First player data: {PLAYERS_DATA_GLOBAL[0]}\")\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] All algorithms (HC, SA, GA) will be run {NUM_RUNS} times each in parallel (where applicable).\")\n",
    "    \n",
    "    all_results_summary = []\n",
    "    num_processes = min(NUM_RUNS, os.cpu_count() if os.cpu_count() else 1)\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Using {num_processes} processes for parallel execution.\")\n",
    "\n",
    "\n",
    "    # --- 1. Hill Climbing --- \n",
    "    hc_section_start_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] --- Starting Hill Climbing Algorithm ({NUM_RUNS} runs in parallel) ---\")\n",
    "    \n",
    "    hc_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, 1000) for i in range(NUM_RUNS)]\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        hc_results_parallel = pool.starmap(run_hill_climbing_trial, hc_params_for_runs)\n",
    "\n",
    "    hc_all_solutions = [res[0] for res in hc_results_parallel if res is not None and res[0] is not None]\n",
    "    hc_all_fitness_values = [res[1] for res in hc_results_parallel if res is not None]\n",
    "    hc_all_exec_times = [res[2] for res in hc_results_parallel if res is not None]\n",
    "    hc_all_histories = [res[3] for res in hc_results_parallel if res is not None]\n",
    "\n",
    "    best_hc_fitness_overall = float(\"inf\")\n",
    "    best_hc_solution_overall = None\n",
    "    best_hc_history_overall = []\n",
    "    if hc_all_solutions:\n",
    "        for i, fit_val in enumerate(hc_all_fitness_values):\n",
    "            if not np.isnan(fit_val) and fit_val < best_hc_fitness_overall:\n",
    "                if i < len(hc_all_solutions) and i < len(hc_all_histories):\n",
    "                    best_hc_fitness_overall = fit_val\n",
    "                    best_hc_solution_overall = hc_all_solutions[i] \n",
    "                    best_hc_history_overall = hc_all_histories[i]\n",
    "    \n",
    "    hc_mean_fitness = np.nanmean([f for f in hc_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in hc_all_fitness_values) else float(\"nan\")\n",
    "    hc_std_fitness = np.nanstd([f for f in hc_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in hc_all_fitness_values) else float(\"nan\")\n",
    "    hc_mean_exec_time = np.nanmean([t for t in hc_all_exec_times if not np.isnan(t)]) if any(not np.isnan(t) for t in hc_all_exec_times) else float(\"nan\")\n",
    "\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Hill Climbing ({NUM_RUNS} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {hc_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {hc_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {hc_mean_exec_time:.2f}s\")\n",
    "    if best_hc_solution_overall:\n",
    "        print(f\"  Overall Best HC Fitness: {best_hc_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Hill Climbing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "            \"Overall Best Fitness\": best_hc_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        if best_hc_history_overall:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_hc_history_overall, marker=\"o\", linestyle=\"-\")\n",
    "            plt.title(f\"Hill Climbing Convergence (Best of {NUM_RUNS} MP Runs)\")\n",
    "            plt.xlabel(\"Improvement Step\")\n",
    "            plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"hc_convergence_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] Saved Hill Climbing convergence plot to {IMAGES_MP_DIR}/hc_convergence_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "    else:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] Hill Climbing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Hill Climbing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "            \"Overall Best Fitness\": float(\"nan\"),\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    hc_section_end_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Hill Climbing section took {hc_section_end_time - hc_section_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "\n",
    "    # --- 2. Simulated Annealing --- \n",
    "    sa_section_start_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] --- Starting Simulated Annealing Algorithm ({NUM_RUNS} runs in parallel) ---\")\n",
    "    \n",
    "    sa_params = {\n",
    "        \"initial_temp\": 1000,\n",
    "        \"final_temp\": 0.1,\n",
    "        \"alpha\": 0.99,\n",
    "        \"iterations_per_temp\": 50\n",
    "    }\n",
    "    sa_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, sa_params) for i in range(NUM_RUNS)]\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        sa_results_parallel = pool.starmap(run_simulated_annealing_trial, sa_params_for_runs)\n",
    "\n",
    "    sa_all_solutions = [res[0] for res in sa_results_parallel if res is not None and res[0] is not None]\n",
    "    sa_all_fitness_values = [res[1] for res in sa_results_parallel if res is not None]\n",
    "    sa_all_exec_times = [res[2] for res in sa_results_parallel if res is not None]\n",
    "    sa_all_histories = [res[3] for res in sa_results_parallel if res is not None]\n",
    "\n",
    "    best_sa_fitness_overall = float(\"inf\")\n",
    "    best_sa_solution_overall = None\n",
    "    best_sa_history_overall = []\n",
    "    if sa_all_solutions:\n",
    "        for i, fit_val in enumerate(sa_all_fitness_values):\n",
    "            if not np.isnan(fit_val) and fit_val < best_sa_fitness_overall:\n",
    "                if i < len(sa_all_solutions) and i < len(sa_all_histories):\n",
    "                    best_sa_fitness_overall = fit_val\n",
    "                    best_sa_solution_overall = sa_all_solutions[i]\n",
    "                    best_sa_history_overall = sa_all_histories[i]\n",
    "\n",
    "    sa_mean_fitness = np.nanmean([f for f in sa_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in sa_all_fitness_values) else float(\"nan\")\n",
    "    sa_std_fitness = np.nanstd([f for f in sa_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in sa_all_fitness_values) else float(\"nan\")\n",
    "    sa_mean_exec_time = np.nanmean([t for t in sa_all_exec_times if not np.isnan(t)]) if any(not np.isnan(t) for t in sa_all_exec_times) else float(\"nan\")\n",
    "\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Simulated Annealing ({NUM_RUNS} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {sa_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {sa_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {sa_mean_exec_time:.2f}s\")\n",
    "    if best_sa_solution_overall:\n",
    "        print(f\"  Overall Best SA Fitness: {best_sa_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Simulated Annealing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "            \"Overall Best Fitness\": best_sa_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        if best_sa_history_overall:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_sa_history_overall, marker=\".\", linestyle=\"-\")\n",
    "            plt.title(f\"Simulated Annealing Convergence (Best of {NUM_RUNS} MP Runs)\")\n",
    "            plt.xlabel(\"Temperature Step / Iteration\")\n",
    "            plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"sa_convergence_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] Saved Simulated Annealing convergence plot to {IMAGES_MP_DIR}/sa_convergence_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "    else:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] Simulated Annealing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Simulated Annealing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "            \"Overall Best Fitness\": float(\"nan\"),\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    sa_section_end_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Simulated Annealing section took {sa_section_end_time - sa_section_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "\n",
    "    # --- 3. Genetic Algorithms --- \n",
    "    ga_section_start_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] --- Starting Genetic Algorithms ({NUM_RUNS} runs per config in parallel) ---\")\n",
    "\n",
    "    ga_configurations = {\n",
    "        \"GA_Config_1_SwapConst1PtPreferVTournVarK\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_swap_constrained,\n",
    "            \"mutation_rate\": 0.1,\n",
    "            \"crossover_op\": crossover_one_point_prefer_valid,\n",
    "            \"selection_op\": selection_tournament_variable_k,\n",
    "            \"tournament_k\": 3,\n",
    "            \"elitism_size\": 2\n",
    "        },\n",
    "        \"GA_Config_2_TargetExchUnifPreferVRanking\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_targeted_player_exchange,\n",
    "            \"mutation_rate\": 0.15,\n",
    "            \"crossover_op\": crossover_uniform_prefer_valid,\n",
    "            \"selection_op\": selection_ranking,\n",
    "            \"elitism_size\": 2\n",
    "        },\n",
    "        \"GA_Config_3_ShuffleWithin1PtPreferVBoltzmann\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_shuffle_within_team_constrained,\n",
    "            \"mutation_rate\": 0.05,\n",
    "            \"crossover_op\": crossover_one_point_prefer_valid,\n",
    "            \"selection_op\": selection_boltzmann,\n",
    "            \"elitism_size\": 1\n",
    "        },\n",
    "        \"GA_Config_4_TargetExchUnifPreferVTournVarK_k5\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_targeted_player_exchange, \n",
    "            \"mutation_rate\": 0.1,\n",
    "            \"crossover_op\": crossover_uniform_prefer_valid,\n",
    "            \"selection_op\": selection_tournament_variable_k,\n",
    "            \"tournament_k\": 5,\n",
    "            \"elitism_size\": 3\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for config_name, ga_params_dict in ga_configurations.items():\n",
    "        config_start_time = time.time()\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  [{timestamp}] Processing GA Configuration: {config_name} ({NUM_RUNS} runs in parallel)\")\n",
    "\n",
    "        ga_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, ga_params_dict, config_name) for i in range(NUM_RUNS)]\n",
    "\n",
    "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "            ga_results_parallel = pool.starmap(run_genetic_algorithm_trial, ga_params_for_runs)\n",
    "        \n",
    "        ga_all_solutions_config = [res[0] for res in ga_results_parallel if res is not None and res[0] is not None]\n",
    "        ga_all_fitness_values_config = [res[1] for res in ga_results_parallel if res is not None]\n",
    "        ga_all_exec_times_config = [res[2] for res in ga_results_parallel if res is not None]\n",
    "        ga_all_histories_config = [res[3] for res in ga_results_parallel if res is not None]\n",
    "\n",
    "        best_ga_fitness_config = float(\"inf\")\n",
    "        best_ga_solution_config = None\n",
    "        best_ga_history_config = []\n",
    "        if ga_all_solutions_config:\n",
    "            for i, fit_val in enumerate(ga_all_fitness_values_config):\n",
    "                if not np.isnan(fit_val) and fit_val < best_ga_fitness_config:\n",
    "                    if i < len(ga_all_solutions_config) and i < len(ga_all_histories_config):\n",
    "                        best_ga_fitness_config = fit_val\n",
    "                        best_ga_solution_config = ga_all_solutions_config[i]\n",
    "                        best_ga_history_config = ga_all_histories_config[i]\n",
    "\n",
    "        ga_mean_fitness_config = np.nanmean([f for f in ga_all_fitness_values_config if not np.isnan(f)]) if any(not np.isnan(f) for f in ga_all_fitness_values_config) else float(\"nan\")\n",
    "        ga_std_fitness_config = np.nanstd([f for f in ga_all_fitness_values_config if not np.isnan(f)]) if any(not np.isnan(f) for f in ga_all_fitness_values_config) else float(\"nan\")\n",
    "        ga_mean_exec_time_config = np.nanmean([t for t in ga_all_exec_times_config if not np.isnan(t)]) if any(not np.isnan(t) for t in ga_all_exec_times_config) else float(\"nan\")\n",
    "\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"    [{timestamp}] GA Config {config_name} ({NUM_RUNS} runs) - Mean Fitness: {ga_mean_fitness_config:.4f}, Std Dev Fitness: {ga_std_fitness_config:.4f}, Mean Exec Time: {ga_mean_exec_time_config:.2f}s\")\n",
    "        if best_ga_solution_config:\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"    [{timestamp}] GA Config {config_name} - Overall Best Fitness: {best_ga_fitness_config:.4f}\")\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": f\"GA: {config_name} (MP-{NUM_RUNS} runs)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": best_ga_fitness_config,\n",
    "                \"Mutation Op\": ga_params_dict[\"mutation_op\"].__name__,\n",
    "                \"Crossover Op\": ga_params_dict[\"crossover_op\"].__name__,\n",
    "                \"Selection Op\": ga_params_dict[\"selection_op\"].__name__\n",
    "            })\n",
    "            if best_ga_history_config and isinstance(best_ga_history_config[0], (int, float, np.number)):\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(best_ga_history_config, marker=\"o\", linestyle=\"-\", markersize=4)\n",
    "                plt.title(f\"GA Convergence: {config_name} (Best of {NUM_RUNS} MP Runs)\")\n",
    "                plt.xlabel(\"Generation\")\n",
    "                plt.ylabel(\"Best Fitness in Population\")\n",
    "                plt.grid(True)\n",
    "                plt.savefig(os.path.join(IMAGES_MP_DIR, f\"ga_convergence_{config_name}_mp_{NUM_RUNS}runs.png\"))\n",
    "                timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(f\"    [{timestamp}] Saved GA convergence plot to {IMAGES_MP_DIR}/ga_convergence_{config_name}_mp_{NUM_RUNS}runs.png\")\n",
    "                plt.close()\n",
    "            elif best_ga_history_config:\n",
    "                 timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                 print(f\"    [{timestamp}] GA Config {config_name} - Fitness history for best run is not in the expected format for plotting (e.g. list of numbers). Type: {type(best_ga_history_config[0])}\")\n",
    "            else:\n",
    "                timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(f\"    [{timestamp}] No valid fitness history to plot for GA config {config_name}.\")\n",
    "        else:\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"    [{timestamp}] GA Config {config_name} did not find any valid solution across all runs that produced a best overall.\")\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": f\"GA: {config_name} (MP-{NUM_RUNS} runs)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": float(\"nan\"),\n",
    "                \"Mutation Op\": ga_params_dict[\"mutation_op\"].__name__,\n",
    "                \"Crossover Op\": ga_params_dict[\"crossover_op\"].__name__,\n",
    "                \"Selection Op\": ga_params_dict[\"selection_op\"].__name__\n",
    "            })\n",
    "        config_end_time = time.time()\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"    [{timestamp}] GA Config {config_name} section took {config_end_time - config_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "    ga_section_end_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Genetic Algorithms section took {ga_section_end_time - ga_section_start_time:.2f} seconds (wall time for all configs).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fefbd",
   "metadata": {},
   "source": [
    "    # ## Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89208429",
   "metadata": {},
   "outputs": [],
   "source": [
    "    results_df = pd.DataFrame(all_results_summary)\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] --- Overall Results Summary ({NUM_RUNS} MP Runs) ---\")\n",
    "    print(results_df.to_string())\n",
    "    results_df.to_csv(os.path.join(IMAGES_MP_DIR, f\"all_algorithms_summary_mp_{NUM_RUNS}runs.csv\"), index=False)\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Saved results summary to {IMAGES_MP_DIR}/all_algorithms_summary_mp_{NUM_RUNS}runs.csv\")\n",
    "\n",
    "    if not results_df.empty:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plot_df_times = results_df.dropna(subset=[\"Mean Exec Time (s)\"])\n",
    "        if not plot_df_times.empty:\n",
    "            alg_names_times = [name.replace(f\" (MP-{NUM_RUNS} runs)\", \"\") for name in plot_df_times[\"Algorithm\"]]\n",
    "            bars = plt.bar(alg_names_times, plot_df_times[\"Mean Exec Time (s)\"], color=plt.cm.viridis(np.linspace(0, 1, len(plot_df_times))))\n",
    "            plt.xlabel(\"Algorithm / Configuration\")\n",
    "            plt.ylabel(\"Mean Execution Time per Run (s)\")\n",
    "            plt.title(f\"Comparative Mean Execution Times ({NUM_RUNS} MP Runs)\")\n",
    "            plt.xticks(rotation=60, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            for bar in bars:\n",
    "                yval = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.05 * yval, f'{yval:.2f}s', ha='center', va='bottom')\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"comparative_times_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] Saved comparative execution times plot.\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] No valid data for comparative execution times plot after dropping NaNs.\")\n",
    "\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plot_df_fitness = results_df.dropna(subset=[\"Overall Best Fitness\"])\n",
    "        if not plot_df_fitness.empty:\n",
    "            alg_names_fitness = [name.replace(f\" (MP-{NUM_RUNS} runs)\", \"\") for name in plot_df_fitness[\"Algorithm\"]]\n",
    "            bars = plt.bar(alg_names_fitness, plot_df_fitness[\"Overall Best Fitness\"], color=plt.cm.plasma(np.linspace(0, 1, len(plot_df_fitness))))\n",
    "            plt.xlabel(\"Algorithm / Configuration\")\n",
    "            plt.ylabel(\"Overall Best Fitness Achieved\")\n",
    "            plt.title(f\"Comparative Overall Best Fitness ({NUM_RUNS} MP Runs)\")\n",
    "            plt.xticks(rotation=60, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            for bar in bars:\n",
    "                yval = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.05 * yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"comparative_fitness_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] Saved comparative best fitness plot.\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"[{timestamp}] No valid data for comparative best fitness plot after dropping NaNs.\")\n",
    "\n",
    "    else:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] No results to plot for summary.\")\n",
    "\n",
    "    # --- 4. Save Summary Results ---\n",
    "    if all_results_summary:\n",
    "        results_df = pd.DataFrame(all_results_summary)\n",
    "        summary_file_path = os.path.join(IMAGES_MP_DIR, f\"all_algorithms_summary_mp_{NUM_RUNS}runs.csv\")\n",
    "        results_df.to_csv(summary_file_path, index=False)\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] Saved all algorithms summary to {summary_file_path}\")\n",
    "    else:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{timestamp}] No results to save in summary CSV.\")\n",
    "\n",
    "    script_total_end_time = time.time()\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] Multiprocessing Script execution finished.\")\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Total script execution time: {script_total_end_time - script_total_start_time:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
