{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ff45b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a668bc",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This work presents a constrained combinatorial optimization approach to the **Sports League Assignment Problem** using **Genetic Algorithms (GAs)**. The objective is to allocate a fixed pool of professional players into a set of 5 structurally valid teams in such a way that the **standard deviation of the teams\\\" average skill ratings** is minimized\u2014promoting competitive balance across the league.\n",
    "\n",
    "Each player is defined by three attributes: **position** (one of `GK`, `DEF`, `MID`, `FWD`), **skill rating** (a numerical measure of ability), and **cost** (in million euros). A valid solution must satisfy the following **hard constraints**:\n",
    "\n",
    "- Each team must consist of exactly **7 players**, with a specific positional structure: **1 GK, 2 DEF, 2 MID, and 2 FWD**\n",
    "- Each team must have a **total cost \u2264 750 million \u20ac**\n",
    "- Each player must be assigned to **exactly one team** (no overlaps)\n",
    "\n",
    "The **search space** is therefore highly constrained and discrete, and infeasible configurations are explicitly excluded from the solution space. The optimization objective is to identify league configurations where teams are not only valid but also **skill-balanced**, quantified by the **standard deviation of average skill ratings across teams**, which serves as the **fitness function** (to be minimized).\n",
    "\n",
    "To address this, we implement a domain-adapted **Genetic Algorithm framework** featuring:\n",
    "\n",
    "- A custom **representation** based on team-to-player mappings\n",
    "- Validity-preserving **mutation** and **crossover** operators\n",
    "- Multiple **selection mechanisms**\n",
    "- Optional **elitism** and population-level diversity handling\n",
    "\n",
    "This report provides a formal problem definition, details the design of the solution encoding and operators, and presents empirical results comparing different GA configurations. The overall objective is to evaluate how well GA-based metaheuristics can navigate this complex constrained search space and evolve solutions that both satisfy domain constraints and optimize league balance.\n",
    "\n",
    "In addition to Genetic Algorithms, this project also explores and evaluates alternative optimization strategies, such as **Hill Climbing** and **Simulated Annealing**, which are well-suited for navigating discrete and constrained search spaces. These algorithms offer different trade-offs in terms of exploration, exploitation, and convergence speed. By implementing and benchmarking multiple approaches on the same problem, we aim to gain deeper insights into their relative effectiveness and robustness when applied to complex constrained optimization tasks such as the Sports League Assignment. This comparative analysis enhances the interpretability of results and supports a broader understanding of the strengths and limitations of population-based versus local search-based heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb935f9",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Critical Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os # Added for path joining\n",
    "import multiprocessing # Added for multiprocessing\n",
    "\n",
    "from solution import LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n",
    "from evolution import genetic_algorithm, hill_climbing, simulated_annealing \n",
    "from operators import (\n",
    "    # Base Mutations\n",
    "    mutate_swap,\n",
    "    mutate_team_shift,\n",
    "    mutate_shuffle_team,\n",
    "    # New/Adapted Mutations\n",
    "    mutate_swap_constrained,\n",
    "    mutate_targeted_player_exchange,\n",
    "    mutate_shuffle_within_team_constrained,\n",
    "    # Base Crossovers\n",
    "    crossover_one_point,\n",
    "    crossover_uniform,\n",
    "    # New/Adapted Crossovers\n",
    "    crossover_one_point_prefer_valid,\n",
    "    crossover_uniform_prefer_valid,\n",
    "    # Selection Operators\n",
    "    selection_ranking,\n",
    "    selection_tournament_variable_k,\n",
    "    selection_boltzmann\n",
    ")\n",
    "\n",
    "# Define number of runs for stochastic algorithms\n",
    "NUM_RUNS = 1 # Parameter for number of runs (e.g., 1, 5, 10, 30) - SET FOR CURRENT TEST\n",
    "\n",
    "# Define the directory for saving graphs and results\n",
    "MULTIPROCESSING_RESULTS_DIR = f\"/home/ubuntu/CIFO_EXTENDED_Project/images_mp/run_{NUM_RUNS}_results\" # Dynamic based on NUM_RUNS\n",
    "IMAGES_MP_DIR = MULTIPROCESSING_RESULTS_DIR\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(IMAGES_MP_DIR):\n",
    "    os.makedirs(IMAGES_MP_DIR)\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Created directory: {IMAGES_MP_DIR}\")\n",
    "\n",
    "# Load player data (globally for worker processes to access if needed, though it's better to pass it)\n",
    "players_df = pd.read_csv(\"players.csv\", sep=\";\")\n",
    "PLAYERS_DATA_GLOBAL = players_df.to_dict(orient=\"records\") # Renamed for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a450a69c",
   "metadata": {},
   "source": [
    "## Cell 2: Further Setup, Data Inspection, and Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583df30",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "all_results_summary = []\n",
    "# Define problem parameters\n",
    "NUM_TEAMS = 5\n",
    "TEAM_SIZE = 7\n",
    "MAX_BUDGET = 750\n",
    "\n",
    "# Define number of runs for stochastic algorithms (and now Hill Climbing)\n",
    "NUM_RUNS = 1 # Parameter for number of runs (e.g., 10, 30) - TEST RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499755d",
   "metadata": {},
   "source": [
    "## Problem Representation Details (from original notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf0ef6",
   "metadata": {},
   "source": [
    "### A. Team-based Representation (Structured Encoding)\n",
    "\n",
    "Let:\n",
    "\n",
    "- $P = \\{p_1, p_2, \\dots, p_{35}\\}$ be the set of players  \n",
    "- $T = \\{t_1, t_2, \\dots, t_5\\}$ be the set of teams\n",
    "\n",
    "Define the assignment function:\n",
    "\n",
    "$$\n",
    "A: P \\rightarrow T\n",
    "$$\n",
    "\n",
    "such that each player is assigned to exactly one team, and the following constraints are satisfied:\n",
    "\n",
    "**Team Size:**\n",
    "\n",
    "$$\n",
    "\\forall t_j \\in T,\\quad \\left|\\{p_i \\in P \\mid A(p_i) = t_j\\}\\right| = 7\n",
    "$$\n",
    "\n",
    "**Positional Requirements:** For each team $t_j \\in T$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&|\\{p_i \\in P \\mid A(p_i) = t_j \\land pos(p_i) = \\text{GK}\\}| = 1 \\\\\n",
    "&|\\{p_i \\in P \\mid A(p_i) = t_j \\land pos(p_i) = \\text{DEF}\\}| = 2 \\\\\n",
    "&|\\{p_i \\in P \\mid A(p_i) = t_j \\land pos(p_i) = \\text{MID}\\}| = 2 \\\\\n",
    "&|\\{p_i \\in P \\mid A(p_i) = t_j \\land pos(p_i) = \\text{FWD}\\}| = 2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Budget Constraint:**\n",
    "\n",
    "$$\n",
    "\\forall t_j \\in T,\\quad \\sum_{p_i \\in P \\mid A(p_i) = t_j} cost(p_i) \\leq 750\n",
    "$$\n",
    "\n",
    "**Objective Function:** Minimize the standard deviation of average team skill:\n",
    "\n",
    "$$\n",
    "f(A) = \\sigma\\left(\\left\\{\\frac{1}{7} \\sum_{p_i \\in P \\mid A(p_i) = t_j} skill(p_i) \\,\\middle|\\, t_j \\in T\\right\\}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b57a1",
   "metadata": {},
   "source": [
    "### B. Player-assignment Representation (Linear Encoding) - This is what is implemented\n",
    "\n",
    "Let:\n",
    "\n",
    "- $P = \\{p_1, p_2, \\dots, p_{35}\\}$ be the set of players  \n",
    "- $T = \\{0, 1, 2, 3, 4\\}$ be team IDs\n",
    "\n",
    "A solution is represented by a vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{a} = [a_1, a_2, \\dots, a_{35}] \\in T^{35}\n",
    "$$\n",
    "\n",
    "where $a_i$ is the team assignment for player $p_i$.\n",
    "\n",
    "**Team Definitions:**\n",
    "\n",
    "$$\n",
    "P_j = \\{p_i \\in P \\mid a_i = j\\}, \\quad \\forall j \\in T\n",
    "$$\n",
    "\n",
    "**Constraints:**\n",
    "\n",
    "$$\n",
    "|P_j| = 7 \\quad \\text{and}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&|\\{p \\in P_j \\mid pos(p) = \\text{GK}\\}| = 1 \\\\\n",
    "&|\\{p \\in P_j \\mid pos(p) = \\text{DEF}\\}| = 2 \\\\\n",
    "&|\\{p \\in P_j \\mid pos(p) = \\text{MID}\\}| = 2 \\\\\n",
    "&|\\{p \\in P_j \\mid pos(p) = \\text{FWD}\\}| = 2 \\\\\n",
    "&\\sum_{p \\in P_j} cost(p) \\leq 750\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Objective Function:**\n",
    "\n",
    "$$\n",
    "f(\\mathbf{a}) = \\sigma\\left(\\left\\{\\frac{1}{7} \\sum_{p \\in P_j} skill(p) \\,\\middle|\\, j \\in T\\right\\}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18874185",
   "metadata": {},
   "source": [
    "## Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630829d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    script_total_start_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Single-Processor Script execution started.\")\n",
    "\n",
    "    data_load_start_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Loading player data...\")\n",
    "    # Player data is already loaded globally\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Player data loaded successfully. Total players: {len(players_data)}\")\n",
    "    if players_data:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] First player data: {players_data[0]}\")\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] All algorithms (HC, SA, GA) will be run {NUM_RUNS} times each.\")\n",
    "    data_load_end_time = time.time()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Data loading and setup took {data_load_end_time - data_load_start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a30ce4",
   "metadata": {},
   "source": [
    "    # ## 1. Hill Climbing\n",
    "    #\n",
    "    # Hill Climbing is a local search algorithm. While a single run from a specific starting point is deterministic, running it multiple times from different random initial solutions provides a more robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7baf08a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hc_section_start_time = time.time()\n",
    "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Hill Climbing Algorithm ({NUM_RUNS} runs) ---\")\n",
    "\n",
    "hc_all_fitness_values = []\n",
    "hc_all_exec_times = []\n",
    "best_hc_solution_overall = None\n",
    "best_hc_fitness_overall = float(\"inf\")\n",
    "best_hc_history_overall = [] # For the best run\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] HC Run {i+1}/{NUM_RUNS}...\")\n",
    "    start_time_hc_run = time.time()\n",
    "    \n",
    "    initial_hc_solution_run = LeagueHillClimbingSolution(players_data, num_teams=NUM_TEAMS, team_size=TEAM_SIZE, max_budget=MAX_BUDGET)\n",
    "    retry_attempts_hc = 0\n",
    "    max_retry_hc = 5\n",
    "    while not initial_hc_solution_run.is_valid() and retry_attempts_hc < max_retry_hc:\n",
    "        print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] HC Run {i+1}: Initial solution invalid, retrying generation ({retry_attempts_hc+1})...\")\n",
    "        initial_hc_solution_run = LeagueHillClimbingSolution(players_data, num_teams=NUM_TEAMS, team_size=TEAM_SIZE, max_budget=MAX_BUDGET)\n",
    "        retry_attempts_hc += 1\n",
    "    \n",
    "    if not initial_hc_solution_run.is_valid():\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] HC Run {i+1} failed to create a valid initial solution after {max_retry_hc} retries. Skipping run.\")\n",
    "        hc_all_fitness_values.append(float('nan'))\n",
    "        hc_all_exec_times.append(float('nan'))\n",
    "        continue\n",
    "\n",
    "    hc_solution_obj_run, hc_fitness_val_run, hc_history_convergence_run = hill_climbing(\n",
    "        initial_solution=initial_hc_solution_run, \n",
    "        players_data=players_data, \n",
    "        max_iterations=1000, \n",
    "        verbose=False\n",
    "    )\n",
    "    end_time_hc_run = time.time()\n",
    "    hc_exec_time_run = end_time_hc_run - start_time_hc_run\n",
    "    \n",
    "    if hc_solution_obj_run:\n",
    "        hc_all_fitness_values.append(hc_fitness_val_run)\n",
    "        hc_all_exec_times.append(hc_exec_time_run)\n",
    "        if hc_fitness_val_run < best_hc_fitness_overall:\n",
    "            best_hc_fitness_overall = hc_fitness_val_run\n",
    "            best_hc_solution_overall = hc_solution_obj_run\n",
    "            best_hc_history_overall = hc_history_convergence_run\n",
    "    else:\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] HC Run {i+1} did not find a valid solution during search.\")\n",
    "        hc_all_fitness_values.append(float('nan'))\n",
    "        hc_all_exec_times.append(float('nan'))\n",
    "\n",
    "hc_mean_fitness = np.nanmean(hc_all_fitness_values) if hc_all_fitness_values else float(\"nan\")\n",
    "hc_std_fitness = np.nanstd(hc_all_fitness_values) if hc_all_fitness_values else float(\"nan\")\n",
    "hc_mean_exec_time = np.nanmean(hc_all_exec_times) if hc_all_exec_times else float(\"nan\")\n",
    "\n",
    "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing ({NUM_RUNS} runs) processing finished.\")\n",
    "print(f\"  Mean Best Fitness: {hc_mean_fitness:.4f}\")\n",
    "print(f\"  Std Dev Best Fitness: {hc_std_fitness:.4f}\")\n",
    "print(f\"  Mean Execution Time per run: {hc_mean_exec_time:.2f}s\")\n",
    "if best_hc_solution_overall:\n",
    "    print(f\"  Overall Best HC Fitness: {best_hc_fitness_overall:.4f}\")\n",
    "    all_results_summary.append({\n",
    "        \"Algorithm\": \"Hill Climbing (SP)\", \n",
    "        \"Mean Fitness\": hc_mean_fitness, \n",
    "        \"Std Dev Fitness\": hc_std_fitness, \n",
    "        \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "        \"Overall Best Fitness\": best_hc_fitness_overall,\n",
    "        \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "    })\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(best_hc_history_overall, marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(f\"Hill Climbing Convergence (Best of {NUM_RUNS} Runs - SP)\")\n",
    "    plt.xlabel(\"Improvement Step\")\n",
    "    plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(IMAGES_SP_DIR, \"hc_convergence_sp.png\")) # Updated path\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved Hill Climbing convergence plot to {IMAGES_SP_DIR}/hc_convergence_sp.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing did not find any valid solution across all runs that produced a best overall.\")\n",
    "    all_results_summary.append({\n",
    "        \"Algorithm\": \"Hill Climbing (SP)\", \n",
    "        \"Mean Fitness\": hc_mean_fitness, \n",
    "        \"Std Dev Fitness\": hc_std_fitness, \n",
    "        \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "        \"Overall Best Fitness\": float('nan'),\n",
    "        \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "    })\n",
    "hc_section_end_time = time.time()\n",
    "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Hill Climbing section took {hc_section_end_time - hc_section_start_time:.2f} seconds.\")\n",
    "\n",
    "# ## 2. Simulated Annealing\n",
    "#\n",
    "# Similar to Hill Climbing, SA is run multiple times from different random initial solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bc1bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sa_section_start_time = time.time()\n",
    "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Simulated Annealing Algorithm ({NUM_RUNS} runs) ---\")\n",
    "\n",
    "sa_all_fitness_values = []\n",
    "sa_all_exec_times = []\n",
    "best_sa_solution_overall = None\n",
    "best_sa_fitness_overall = float(\"inf\")\n",
    "best_sa_history_overall = [] # For the best run\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] SA Run {i+1}/{NUM_RUNS}...\")\n",
    "    start_time_sa_run = time.time()\n",
    "    \n",
    "    initial_sa_solution_run = LeagueSASolution(players_data, num_teams=NUM_TEAMS, team_size=TEAM_SIZE, max_budget=MAX_BUDGET)\n",
    "    retry_attempts_sa = 0\n",
    "    max_retry_sa = 5\n",
    "    while not initial_sa_solution_run.is_valid() and retry_attempts_sa < max_retry_sa:\n",
    "        print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] SA Run {i+1}: Initial solution invalid, retrying generation ({retry_attempts_sa+1})...\")\n",
    "        initial_sa_solution_run = LeagueSASolution(players_data, num_teams=NUM_TEAMS, team_size=TEAM_SIZE, max_budget=MAX_BUDGET)\n",
    "        retry_attempts_sa += 1\n",
    "        \n",
    "    if not initial_sa_solution_run.is_valid():\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] SA Run {i+1} failed to create a valid initial solution after {max_retry_sa} retries. Skipping run.\")\n",
    "        sa_all_fitness_values.append(float('nan'))\n",
    "        sa_all_exec_times.append(float('nan'))\n",
    "        continue\n",
    "\n",
    "    sa_solution_obj_run, sa_fitness_val_run, sa_history_convergence_run = simulated_annealing(\n",
    "        initial_solution=initial_sa_solution_run, \n",
    "        players_data=players_data, \n",
    "        initial_temp=1000, \n",
    "        final_temp=1, \n",
    "        alpha=0.99, \n",
    "        iterations_per_temp=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    end_time_sa_run = time.time()\n",
    "    sa_exec_time_run = end_time_sa_run - start_time_sa_run\n",
    "    \n",
    "    if sa_solution_obj_run:\n",
    "        sa_all_fitness_values.append(sa_fitness_val_run)\n",
    "        sa_all_exec_times.append(sa_exec_time_run)\n",
    "        if sa_fitness_val_run < best_sa_fitness_overall:\n",
    "            best_sa_fitness_overall = sa_fitness_val_run\n",
    "            best_sa_solution_overall = sa_solution_obj_run\n",
    "            best_sa_history_overall = sa_history_convergence_run\n",
    "    else:\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] SA Run {i+1} did not find a valid solution during search.\")\n",
    "        sa_all_fitness_values.append(float('nan'))\n",
    "        sa_all_exec_times.append(float('nan'))\n",
    "\n",
    "sa_mean_fitness = np.nanmean(sa_all_fitness_values) if sa_all_fitness_values else float(\"nan\")\n",
    "sa_std_fitness = np.nanstd(sa_all_fitness_values) if sa_all_fitness_values else float(\"nan\")\n",
    "sa_mean_exec_time = np.nanmean(sa_all_exec_times) if sa_all_exec_times else float(\"nan\")\n",
    "\n",
    "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing ({NUM_RUNS} runs) processing finished.\")\n",
    "print(f\"  Mean Best Fitness: {sa_mean_fitness:.4f}\")\n",
    "print(f\"  Std Dev Best Fitness: {sa_std_fitness:.4f}\")\n",
    "print(f\"  Mean Execution Time per run: {sa_mean_exec_time:.2f}s\")\n",
    "if best_sa_solution_overall:\n",
    "    print(f\"  Overall Best SA Fitness: {best_sa_fitness_overall:.4f}\")\n",
    "    all_results_summary.append({\n",
    "        \"Algorithm\": \"Simulated Annealing (SP)\", \n",
    "        \"Mean Fitness\": sa_mean_fitness, \n",
    "        \"Std Dev Fitness\": sa_std_fitness, \n",
    "        \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "        \"Overall Best Fitness\": best_sa_fitness_overall,\n",
    "        \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "    })\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(best_sa_history_overall, marker=\".\", linestyle=\"-\")\n",
    "    plt.title(f\"Simulated Annealing Convergence (Best of {NUM_RUNS} Runs - SP)\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(IMAGES_SP_DIR, \"sa_convergence_sp.png\")) # Updated path\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved Simulated Annealing convergence plot to {IMAGES_SP_DIR}/sa_convergence_sp.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing did not find any valid solution across all runs that produced a best overall.\")\n",
    "    all_results_summary.append({\n",
    "        \"Algorithm\": \"Simulated Annealing (SP)\", \n",
    "        \"Mean Fitness\": sa_mean_fitness, \n",
    "        \"Std Dev Fitness\": sa_std_fitness, \n",
    "        \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "        \"Overall Best Fitness\": float('nan'),\n",
    "        \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "    })\n",
    "sa_section_end_time = time.time()\n",
    "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Simulated Annealing section took {sa_section_end_time - sa_section_start_time:.2f} seconds.\")\n",
    "\n",
    "# ## 3. Genetic Algorithm Configurations\n",
    "#\n",
    "# Multiple GA configurations will be tested, each run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93889d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_section_start_time = time.time()\n",
    "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] --- Starting Genetic Algorithm Configurations ({NUM_RUNS} runs each) ---\")\n",
    "\n",
    "ga_configurations = [\n",
    "    {\"name\": \"GA_Config_1_SwapConst1PtPreferVTournVarK\", \"pop_size\": 50, \"gens\": 75, \"mut_rate\": 0.2, \"elite\": 5, \"mut_op\": mutate_swap_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_tournament_variable_k, \"tourn_k\": 3, \"boltz_temp\": None}, # Original best from SP\n",
    "    {\"name\": \"GA_Config_2_TargetExchUnifPreferVRank\", \"pop_size\": 50, \"gens\": 75, \"mut_rate\": 0.2, \"elite\": 5, \"mut_op\": mutate_targeted_player_exchange, \"cross_op\": crossover_uniform_prefer_valid, \"sel_op\": selection_ranking, \"tourn_k\": None, \"boltz_temp\": None},\n",
    "    {\"name\": \"GA_Config_3_ShuffleTeamConst1PtPreferVBoltz\", \"pop_size\": 50, \"gens\": 75, \"mut_rate\": 0.2, \"elite\": 5, \"mut_op\": mutate_shuffle_within_team_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_boltzmann, \"tourn_k\": None, \"boltz_temp\": 100},\n",
    "    # Variations with more generations\n",
    "    {\"name\": \"GA_Config_4_SwapConst1PtPreferVTournVarK_150Gen\", \"pop_size\": 50, \"gens\": 150, \"mut_rate\": 0.2, \"elite\": 5, \"mut_op\": mutate_swap_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_tournament_variable_k, \"tourn_k\": 3, \"boltz_temp\": None},\n",
    "    # Variations with different population sizes\n",
    "    {\"name\": \"GA_Config_5_SwapConst1PtPreferVTournVarK_100Pop\", \"pop_size\": 100, \"gens\": 75, \"mut_rate\": 0.2, \"elite\": 10, \"mut_op\": mutate_swap_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_tournament_variable_k, \"tourn_k\": 3, \"boltz_temp\": None},\n",
    "    # Variations with different mutation rates\n",
    "    {\"name\": \"GA_Config_6_SwapConst1PtPreferVTournVarK_MutRate0.1\", \"pop_size\": 50, \"gens\": 75, \"mut_rate\": 0.1, \"elite\": 5, \"mut_op\": mutate_swap_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_tournament_variable_k, \"tourn_k\": 3, \"boltz_temp\": None},\n",
    "    {\"name\": \"GA_Config_7_SwapConst1PtPreferVTournVarK_MutRate0.3\", \"pop_size\": 50, \"gens\": 75, \"mut_rate\": 0.3, \"elite\": 5, \"mut_op\": mutate_swap_constrained, \"cross_op\": crossover_one_point_prefer_valid, \"sel_op\": selection_tournament_variable_k, \"tourn_k\": 3, \"boltz_temp\": None},\n",
    "]\n",
    "\n",
    "for config in ga_configurations:\n",
    "    config_name_val = config[\"name\"]\n",
    "    timestamp_val = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\n  [{timestamp_val}] Running GA Configuration: {config_name_val}\")\n",
    "    ga_all_fitness_values_config = []\n",
    "    ga_all_exec_times_config = []\n",
    "    best_ga_solution_config_overall = None\n",
    "    best_ga_fitness_config_overall = float(\"inf\")\n",
    "    best_ga_history_config_overall = []\n",
    "\n",
    "    for i in range(NUM_RUNS)        config_name_val = config[\"name\"]\n",
    "        timestamp_val = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        run_count_val = f\"{i+1}/{NUM_RUNS}\"\n",
    "        print(f\"    [{timestamp_val}] GA Run {run_count_val} for {config_name_val}...\")       start_time_ga_run = time.time()\n",
    "        \n",
    "        # Call GA with parameters from config\n",
    "        ga_solution_obj_run, ga_history_convergence_run = genetic_algorithm(\n",
    "            players_data=players_data,\n",
    "            population_size=config[\"pop_size\"],\n",
    "            generations=config[\"gens\"],\n",
    "            mutation_rate=config[\"mut_rate\"],\n",
    "            elite_size=config[\"elite\"],\n",
    "            mutation_operator_func=config[\"mut_op\"],\n",
    "            crossover_operator_func=config[\"cross_op\"],\n",
    "            selection_operator_func=config[\"sel_op\"],\n",
    "            tournament_k=config[\"tourn_k\"] if config[\"tourn_k\"] is not None else 3, # Default for sel_op that needs it\n",
    "            boltzmann_temp=config[\"boltz_temp\"] if config[\"boltz_temp\"] is not None else 100, # Default for sel_op that needs it\n",
    "            num_teams=NUM_TEAMS, \n",
    "            team_size=TEAM_SIZE, \n",
    "            max_budget=MAX_BUDGET,\n",
    "            verbose=False # Set to True for detailed generation logs\n",
    "        )\n",
    "        end_time_ga_run = time.time()\n",
    "        ga_exec_time_run = end_time_ga_run - start_time_ga_run\n",
    "\n",
    "        if ga_solution_obj_run:\n",
    "            ga_fitness_val_run = ga_solution_obj_run.fitness() # MODIFIED: Vectorized call\n",
    "            ga_all_fitness_values_config.append(ga_fitness_val_run)\n",
    "            ga_all_exec_times_config.append(ga_exec_time_run)\n",
    "            if ga_fitness_val_run < best_ga_fitness_config_overall:\n",
    "                best_ga_fitness_config_overall = ga_fitness_val_run\n",
    "                best_ga_solution_config_overall = ga_solution_obj_run\n",
    "                best_ga_history_config_overall = ga_history_convergence_run\n",
    "        else:\n",
    "config_name_val = config[\"name\"]\n",
    "        timestamp_val = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        run_count_val = f\"{i+1}/{NUM_RUNS}\"\n",
    "        print(f\"    [{timestamp_val}] GA Run {run_count_val} for {config_name_val}...\")ot return a valid solution object.\")\n",
    "            ga_all_fitness_values_config.append(float('nan'))\n",
    "            ga_all_exec_times_config.append(float('nan'))\n",
    "\n",
    "    ga_mean_fitness_config = np.nanmean(ga_all_fitness_values_config) if ga_all_fitness_values_config else float(\"nan\")\n",
    "    ga_std_fitness_config = np.nanstd(ga_all_fitness_values_config) if ga_all_fitness_values_config else float(\"nan\")\n",
    "    ga_mean_exec_time_config = np.nanmean(ga_all_exec_times_config) if ga_all_exec_times_config else float(\"nan\")\n",
    "\n",
    "    print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA Configuration {config[\"name\"]} ({NUM_RUNS} runs) processing finished.\")\n",
    "    print(f\"    Mean Best Fitness: {ga_mean_fitness_config:.4f}\")\n",
    "    print(f\"    Std Dev Best Fitness: {ga_std_fitness_config:.4f}\")\n",
    "    print(f\"    Mean Execution Time per run: {ga_mean_exec_time_config:.2f}s\")\n",
    "    if best_ga_solution_config_overall:\n",
    "        print(f\"    Overall Best GA Fitness for {config[\"name\"]}: {best_ga_fitness_config_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": config[\"name\"] + \" (SP)\", \n",
    "            \"Mean Fitness\": ga_mean_fitness_config, \n",
    "            \"Std Dev Fitness\": ga_std_fitness_config, \n",
    "            \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "            \"Overall Best Fitness\": best_ga_fitness_config_overall,\n",
    "            \"Mutation Op\": config[\"mut_op\"].__name__, \n",
    "            \"Crossover Op\": config[\"cross_op\"].__name__, \n",
    "            \"Selection Op\": config[\"sel_op\"].__name__\n",
    "        })\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(best_ga_history_config_overall, marker=\"o\", linestyle=\"-\")\n",
    "        plt.title(f\"GA Convergence ({config[\"name\"]}) - Best of {NUM_RUNS} Runs - SP\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(IMAGES_SP_DIR, f\"ga_convergence_sp_{config[\"name\"]}.png\")) # Updated path\n",
    "        print(f\"    [{time.strftime('%Y-%m-%d %H:%M:%S')}] Saved GA convergence plot to {IMAGES_SP_DIR}/ga_convergence_sp_{config[\"name\"]}.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')}] GA Configuration {config[\"name\"]} did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": config[\"name\"] + \" (SP)\", \n",
    "            \"Mean Fitness\": ga_mean_fitness_config, \n",
    "            \"Std Dev Fitness\": ga_std_fitness_config, \n",
    "            \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "            \"Overall Best Fitness\": float('nan'),\n",
    "            \"Mutation Op\": config[\"mut_op\"].__name__, \n",
    "            \"Crossover Op\": config[\"cross_op\"].__name__, \n",
    "            \"Selection Op\": config[\"sel_op\"].__name__\n",
    "        })\n",
    "ga_section_end_time = time.time()\n",
    "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] All Genetic Algorithm configurations took {ga_section_end_time - ga_section_start_time:.2f} seconds.\")\n",
    "\n",
    "# Convert summary to DataFrame and save\n",
    "summary_df = pd.DataFrame(all_results_summary)\n",
    "summary_filename = os.path.join(IMAGES_SP_DIR, \"all_algorithms_summary_sp.csv\") # Updated path\n",
    "summary_df.to_csv(summary_filename, index=False, sep=\";\")\n",
    "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] Overall summary saved to {summary_filename}\")\n",
    "\n",
    "script_total_end_time = time.time()\n",
    "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Single-Processor Script execution finished. Total time: {script_total_end_time - script_total_start_time:.2f} seconds.\")\n",
    "\n",
    "# Execute the main function if the script is run directly (or cell is executed in notebook)\n",
    "if __name__ == \"__main__\" or __name__ == \"builtins\": # For notebook execution\n",
    "main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979ee10",
   "metadata": {},
   "source": [
    "## Helper Functions for Multiprocessing Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308480da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hill_climbing_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, max_iterations_hc):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Use a slightly different print format to distinguish from SP if needed, or keep consistent\n",
    "    # For now, keeping it similar to the reference MP script for easier comparison during adaptation\n",
    "    print(f\"  [{timestamp}] HC Run {run_id+1}/{NUM_RUNS} starting...\")\n",
    "    start_time_hc_run = time.time()\n",
    "    \n",
    "    # Ensure using the correct class from solution.py (which should be the vectorized one)\n",
    "    initial_hc_solution_run = LeagueHillClimbingSolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "    retry_attempts_hc = 0\n",
    "    max_retry_hc = 5 # Consistent with reference MP script\n",
    "    while not initial_hc_solution_run.is_valid() and retry_attempts_hc < max_retry_hc:\n",
    "        # Verbose print for retries can be kept or removed based on preference\n",
    "        # print(f\"    [{time.strftime(\"%Y-%m-%d %H:%M:%S\")}] HC Run {run_id+1}: Initial solution invalid, retrying generation ({retry_attempts_hc+1})...\")\n",
    "        initial_hc_solution_run = LeagueHillClimbingSolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "        retry_attempts_hc += 1\n",
    "    \n",
    "    if not initial_hc_solution_run.is_valid():\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"  [{timestamp}] HC Run {run_id+1} failed to create a valid initial solution after {max_retry_hc} retries. Skipping run.\")\n",
    "        return None, float(\"nan\"), float(\"nan\"), [] # Return structure consistent with MP script\n",
    "\n",
    "    # Ensure using the correct hill_climbing function from evolution.py (vectorized)\n",
    "    hc_solution_obj_run, hc_fitness_val_run, hc_history_convergence_run = hill_climbing(\n",
    "        initial_solution=initial_hc_solution_run, \n",
    "        players_data=players_data_local, # Pass the local copy\n",
    "        max_iterations=max_iterations_hc, \n",
    "        verbose=False # Keep verbose off for parallel runs to avoid cluttered output\n",
    "    )\n",
    "    end_time_hc_run = time.time()\n",
    "    hc_exec_time_run = end_time_hc_run - start_time_hc_run\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"  [{timestamp}] HC Run {run_id+1} finished in {hc_exec_time_run:.2f}s with fitness {hc_fitness_val_run if hc_solution_obj_run else 'N/A'}.\")\n",
    "    return hc_solution_obj_run, hc_fitness_val_run if hc_solution_obj_run else float(\"nan\"), hc_exec_time_run, hc_history_convergence_run\n",
    "\n",
    "def run_simulated_annealing_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, sa_params_local):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"  [{timestamp}] SA Run {run_id+1}/{NUM_RUNS} starting...\")\n",
    "    start_time_sa_run = time.time()\n",
    "    initial_sa_solution = LeagueSASolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "    retry_attempts_sa = 0\n",
    "    max_retry_sa = 5\n",
    "    while not initial_sa_solution.is_valid() and retry_attempts_sa < max_retry_sa:\n",
    "        # print(f\"    [{time.strftime(\"%Y-%m-%d %H:%M:%S\")}] SA Run {run_id+1}: Initial solution invalid, retrying generation ({retry_attempts_sa+1})...\")\n",
    "        initial_sa_solution = LeagueSASolution(players_data_local, num_teams=num_teams_local, team_size=team_size_local, max_budget=max_budget_local)\n",
    "        retry_attempts_sa += 1\n",
    "\n",
    "    if not initial_sa_solution.is_valid():\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"  [{timestamp}] SA Run {run_id+1} failed to create a valid initial solution after {max_retry_sa} retries. Skipping run.\")\n",
    "        return None, float(\"nan\"), float(\"nan\"), []\n",
    "\n",
    "    # Ensure using the correct simulated_annealing function from evolution.py (vectorized)\n",
    "    sa_solution_run, sa_fitness_run, sa_history_run = simulated_annealing(\n",
    "        initial_solution=initial_sa_solution,\n",
    "        players_data=players_data_local, \n",
    "        initial_temp=sa_params_local[\"initial_temp\"],\n",
    "        final_temp=sa_params_local[\"final_temp\"],\n",
    "        alpha=sa_params_local[\"alpha\"],\n",
    "        iterations_per_temp=sa_params_local[\"iterations_per_temp\"],\n",
    "        verbose=False\n",
    "    )\n",
    "    end_time_sa_run = time.time()\n",
    "    sa_exec_time_run = end_time_sa_run - start_time_sa_run\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"  [{timestamp}] SA Run {run_id+1} finished in {sa_exec_time_run:.2f}s with fitness {sa_fitness_run if sa_solution_run else 'N/A'}.\")\n",
    "    return sa_solution_run, sa_fitness_run if sa_solution_run else float(\"nan\"), sa_exec_time_run, sa_history_run\n",
    "\n",
    "def run_genetic_algorithm_trial(run_id, players_data_local, num_teams_local, team_size_local, max_budget_local, ga_params_local, config_name_local):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Corrected f-string for GA run print statement\n",
    "    print(f\"  [{timestamp}] GA Run {run_id+1}/{NUM_RUNS} for {config_name_local} starting...\")\n",
    "    start_time_ga_run = time.time()\n",
    "    \n",
    "    # Ensure using the correct genetic_algorithm function from evolution.py (vectorized)\n",
    "    best_solution_ga_run, fitness_history_ga_run = genetic_algorithm(\n",
    "        players_data=players_data_local, \n",
    "        population_size=ga_params_local[\"population_size\"],\n",
    "        generations=ga_params_local[\"generations\"],\n",
    "        mutation_rate=ga_params_local[\"mutation_rate\"],\n",
    "        elite_size=ga_params_local[\"elitism_size\"],\n",
    "        mutation_operator_func=ga_params_local[\"mutation_op\"], \n",
    "        crossover_operator_func=ga_params_local[\"crossover_op\"],\n",
    "        selection_operator_func=ga_params_local[\"selection_op\"],\n",
    "        tournament_k=ga_params_local.get(\"tournament_k\", 3), # Consistent with SP and MP ref\n",
    "        boltzmann_temp=ga_params_local.get(\"boltzmann_temp\", 100), # Consistent with SP and MP ref\n",
    "        num_teams=num_teams_local, \n",
    "        team_size=team_size_local,\n",
    "        max_budget=max_budget_local,\n",
    "        verbose=False \n",
    "    )\n",
    "    \n",
    "    end_time_ga_run = time.time()\n",
    "    actual_exec_time_ga_run = end_time_ga_run - start_time_ga_run \n",
    "    best_fitness_ga_run = best_solution_ga_run.fitness() if best_solution_ga_run else float(\"nan\")\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Corrected f-string for GA run print statement\n",
    "    print(f\"  [{timestamp}] GA Run {run_id+1} for {config_name_local} finished in {actual_exec_time_ga_run:.2f}s with fitness {best_fitness_ga_run if best_solution_ga_run else 'N/A'}.\")\n",
    "    return best_solution_ga_run, best_fitness_ga_run, actual_exec_time_ga_run, fitness_history_ga_run\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6325015",
   "metadata": {},
   "source": [
    "## Main Execution Block (Adapted for Multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216201e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    script_total_start_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Consistent print statement with MP reference\n",
    "    print(f\"[{timestamp}] Multiprocessing Script for {NUM_RUNS} runs execution started.\")\n",
    "\n",
    "    # Data loading is already handled globally by PLAYERS_DATA_GLOBAL\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Player data loaded. Total players: {len(PLAYERS_DATA_GLOBAL)}\")\n",
    "    if PLAYERS_DATA_GLOBAL:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] First player data: {PLAYERS_DATA_GLOBAL[0]}\")\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] All algorithms (HC, SA, GA) will be run {NUM_RUNS} times each in parallel (where applicable).\")\n",
    "    \n",
    "    # Initialize results summary list (this was outside main in SP, now inside for MP structure)\n",
    "    all_results_summary = [] \n",
    "    \n",
    "    # Determine number of processes to use\n",
    "    # If NUM_RUNS is 1, it makes sense to use only 1 process, otherwise os.cpu_count() or NUM_RUNS if smaller\n",
    "    num_processes = 1 if NUM_RUNS == 1 else min(NUM_RUNS, os.cpu_count() if os.cpu_count() else 1)\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Using {num_processes} processes for parallel execution.\")\n",
    "\n",
    "    # --- 1. Hill Climbing (Parallel Execution) --- \n",
    "    hc_section_start_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\n[{timestamp}] --- Starting Hill Climbing Algorithm ({NUM_RUNS} runs in parallel) ---\")\n",
    "    \n",
    "    # Prepare parameters for each HC run\n",
    "    # Max iterations for HC can be a parameter, using 1000 as in SP and MP ref\n",
    "    hc_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, 1000) for i in range(NUM_RUNS)]\n",
    "    \n",
    "    # Use multiprocessing Pool for parallel execution\n",
    "    if NUM_RUNS > 1:\n",
    "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "            hc_results_parallel = pool.starmap(run_hill_climbing_trial, hc_params_for_runs)\n",
    "    else: # Single run, no need for pool, call directly for easier debugging if needed\n",
    "        hc_results_parallel = [run_hill_climbing_trial(*hc_params_for_runs[0])]\n",
    "\n",
    "    # Process results from parallel HC runs\n",
    "    hc_all_solutions = [res[0] for res in hc_results_parallel if res is not None and res[0] is not None]\n",
    "    hc_all_fitness_values = [res[1] for res in hc_results_parallel if res is not None]\n",
    "    hc_all_exec_times = [res[2] for res in hc_results_parallel if res is not None]\n",
    "    hc_all_histories = [res[3] for res in hc_results_parallel if res is not None]\n",
    "\n",
    "    best_hc_fitness_overall = float(\"inf\")\n",
    "    best_hc_solution_overall = None\n",
    "    best_hc_history_overall = []\n",
    "    if hc_all_solutions: # Check if any valid solutions were found\n",
    "        for i, fit_val in enumerate(hc_all_fitness_values):\n",
    "            if not np.isnan(fit_val) and fit_val < best_hc_fitness_overall:\n",
    "                # Ensure indices are valid for all lists before accessing\n",
    "                if i < len(hc_all_solutions) and hc_all_solutions[i] is not None and \\\n",
    "                   i < len(hc_all_histories) and hc_all_histories[i] is not None:\n",
    "                    best_hc_fitness_overall = fit_val\n",
    "                    best_hc_solution_overall = hc_all_solutions[i] \n",
    "                    best_hc_history_overall = hc_all_histories[i]\n",
    "    \n",
    "    hc_mean_fitness = np.nanmean([f for f in hc_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in hc_all_fitness_values) else float(\"nan\")\n",
    "    hc_std_fitness = np.nanstd([f for f in hc_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in hc_all_fitness_values) else float(\"nan\")\n",
    "    hc_mean_exec_time = np.nanmean([t for t in hc_all_exec_times if not np.isnan(t)]) if any(not np.isnan(t) for t in hc_all_exec_times) else float(\"nan\")\n",
    "\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Hill Climbing ({NUM_RUNS} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {hc_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {hc_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {hc_mean_exec_time:.2f}s\")\n",
    "    if best_hc_solution_overall:\n",
    "        print(f\"  Overall Best HC Fitness: {best_hc_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Hill Climbing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "            \"Overall Best Fitness\": best_hc_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        if best_hc_history_overall: # Ensure history is not empty\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_hc_history_overall, marker=\"o\", linestyle=\"-\")\n",
    "            plt.title(f\"Hill Climbing Convergence (Best of {NUM_RUNS} MP Runs)\")\n",
    "            plt.xlabel(\"Improvement Step\")\n",
    "            plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "            plt.grid(True)\n",
    "            # Use IMAGES_MP_DIR for saving\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"hc_convergence_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] Saved Hill Climbing convergence plot to {IMAGES_MP_DIR}/hc_convergence_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "    else:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] Hill Climbing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Hill Climbing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": hc_mean_fitness, \n",
    "            \"Std Dev Fitness\": hc_std_fitness, \n",
    "            \"Mean Exec Time (s)\": hc_mean_exec_time,\n",
    "            \"Overall Best Fitness\": float(\"nan\"), # Consistent with MP ref\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    hc_section_end_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Hill Climbing section took {hc_section_end_time - hc_section_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "    # --- 2. Simulated Annealing (Parallel Execution) --- \n",
    "    sa_section_start_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\n[{timestamp}] --- Starting Simulated Annealing Algorithm ({NUM_RUNS} runs in parallel) ---\")\n",
    "    \n",
    "    # SA parameters from MP reference (can be adjusted)\n",
    "    sa_params = {\n",
    "        \"initial_temp\": 1000,\n",
    "        \"final_temp\": 0.1, # MP ref used 0.1, SP used 1\n",
    "        \"alpha\": 0.99,\n",
    "        \"iterations_per_temp\": 50 # MP ref used 50, SP used 100\n",
    "    }\n",
    "    sa_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, sa_params) for i in range(NUM_RUNS)]\n",
    "\n",
    "    if NUM_RUNS > 1:\n",
    "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "            sa_results_parallel = pool.starmap(run_simulated_annealing_trial, sa_params_for_runs)\n",
    "    else:\n",
    "        sa_results_parallel = [run_simulated_annealing_trial(*sa_params_for_runs[0])]\n",
    "\n",
    "    sa_all_solutions = [res[0] for res in sa_results_parallel if res is not None and res[0] is not None]\n",
    "    sa_all_fitness_values = [res[1] for res in sa_results_parallel if res is not None]\n",
    "    sa_all_exec_times = [res[2] for res in sa_results_parallel if res is not None]\n",
    "    sa_all_histories = [res[3] for res in sa_results_parallel if res is not None]\n",
    "\n",
    "    best_sa_fitness_overall = float(\"inf\")\n",
    "    best_sa_solution_overall = None\n",
    "    best_sa_history_overall = []\n",
    "    if sa_all_solutions:\n",
    "        for i, fit_val in enumerate(sa_all_fitness_values):\n",
    "            if not np.isnan(fit_val) and fit_val < best_sa_fitness_overall:\n",
    "                if i < len(sa_all_solutions) and sa_all_solutions[i] is not None and \\\n",
    "                   i < len(sa_all_histories) and sa_all_histories[i] is not None:\n",
    "                    best_sa_fitness_overall = fit_val\n",
    "                    best_sa_solution_overall = sa_all_solutions[i]\n",
    "                    best_sa_history_overall = sa_all_histories[i]\n",
    "\n",
    "    sa_mean_fitness = np.nanmean([f for f in sa_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in sa_all_fitness_values) else float(\"nan\")\n",
    "    sa_std_fitness = np.nanstd([f for f in sa_all_fitness_values if not np.isnan(f)]) if any(not np.isnan(f) for f in sa_all_fitness_values) else float(\"nan\")\n",
    "    sa_mean_exec_time = np.nanmean([t for t in sa_all_exec_times if not np.isnan(t)]) if any(not np.isnan(t) for t in sa_all_exec_times) else float(\"nan\")\n",
    "\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Simulated Annealing ({NUM_RUNS} runs) processing finished.\")\n",
    "    print(f\"  Mean Best Fitness: {sa_mean_fitness:.4f}\")\n",
    "    print(f\"  Std Dev Best Fitness: {sa_std_fitness:.4f}\")\n",
    "    print(f\"  Mean Execution Time per run: {sa_mean_exec_time:.2f}s\")\n",
    "    if best_sa_solution_overall:\n",
    "        print(f\"  Overall Best SA Fitness: {best_sa_fitness_overall:.4f}\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Simulated Annealing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "            \"Overall Best Fitness\": best_sa_fitness_overall,\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "        if best_sa_history_overall:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_sa_history_overall, marker=\".\", linestyle=\"-\") # Marker consistent with MP ref\n",
    "            plt.title(f\"Simulated Annealing Convergence (Best of {NUM_RUNS} MP Runs)\")\n",
    "            plt.xlabel(\"Temperature Step / Iteration\") # Label consistent with MP ref\n",
    "            plt.ylabel(\"Fitness (Std Dev of Avg Team Skills)\")\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"sa_convergence_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] Saved Simulated Annealing convergence plot to {IMAGES_MP_DIR}/sa_convergence_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "    else:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] Simulated Annealing did not find any valid solution across all runs that produced a best overall.\")\n",
    "        all_results_summary.append({\n",
    "            \"Algorithm\": f\"Simulated Annealing (MP-{NUM_RUNS} runs)\", \n",
    "            \"Mean Fitness\": sa_mean_fitness, \n",
    "            \"Std Dev Fitness\": sa_std_fitness, \n",
    "            \"Mean Exec Time (s)\": sa_mean_exec_time,\n",
    "            \"Overall Best Fitness\": float(\"nan\"),\n",
    "            \"Mutation Op\": \"N/A\", \"Crossover Op\": \"N/A\", \"Selection Op\": \"N/A\"\n",
    "        })\n",
    "    sa_section_end_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Simulated Annealing section took {sa_section_end_time - sa_section_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "    # --- 3. Genetic Algorithms (Parallel Execution per Configuration) --- \n",
    "    ga_section_start_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\n[{timestamp}] --- Starting Genetic Algorithms ({NUM_RUNS} runs per config in parallel) ---\")\n",
    "\n",
    "    # GA configurations (can be taken from SP or MP ref, ensuring ops are from current operators.py)\n",
    "    ga_configurations = {\n",
    "        \"GA_Config_1_SwapConst1PtPreferVTournVarK\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_swap_constrained, # from operators.py\n",
    "            \"mutation_rate\": 0.1,\n",
    "            \"crossover_op\": crossover_one_point_prefer_valid, # from operators.py\n",
    "            \"selection_op\": selection_tournament_variable_k, # from operators.py\n",
    "            \"tournament_k\": 3,\n",
    "            \"elitism_size\": 2\n",
    "        },\n",
    "        \"GA_Config_2_TargetExchUnifPreferVRanking\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_targeted_player_exchange,\n",
    "            \"mutation_rate\": 0.15,\n",
    "            \"crossover_op\": crossover_uniform_prefer_valid,\n",
    "            \"selection_op\": selection_ranking,\n",
    "            \"elitism_size\": 2\n",
    "        },\n",
    "        \"GA_Config_3_ShuffleWithin1PtPreferVBoltzmann\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_shuffle_within_team_constrained,\n",
    "            \"mutation_rate\": 0.05,\n",
    "            \"crossover_op\": crossover_one_point_prefer_valid,\n",
    "            \"selection_op\": selection_boltzmann,\n",
    "            \"elitism_size\": 1 # MP ref had 1, SP had 2. Using 1 for now.\n",
    "        },\n",
    "        \"GA_Config_4_TargetExchUnifPreferVTournVarK_k5\": {\n",
    "            \"population_size\": 50,\n",
    "            \"generations\": 100,\n",
    "            \"mutation_op\": mutate_targeted_player_exchange, \n",
    "            \"mutation_rate\": 0.1,\n",
    "            \"crossover_op\": crossover_uniform_prefer_valid,\n",
    "            \"selection_op\": selection_tournament_variable_k,\n",
    "            \"tournament_k\": 5,\n",
    "            \"elitism_size\": 3\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for config_name, ga_params_dict in ga_configurations.items():\n",
    "        config_start_time = time.time()\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"  [{timestamp}] Processing GA Configuration: {config_name} ({NUM_RUNS} runs in parallel)\")\n",
    "\n",
    "        ga_params_for_runs = [(i, PLAYERS_DATA_GLOBAL, NUM_TEAMS, TEAM_SIZE, MAX_BUDGET, ga_params_dict, config_name) for i in range(NUM_RUNS)]\n",
    "\n",
    "        if NUM_RUNS > 1:\n",
    "            with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "                ga_results_parallel = pool.starmap(run_genetic_algorithm_trial, ga_params_for_runs)\n",
    "        else:\n",
    "            ga_results_parallel = [run_genetic_algorithm_trial(*ga_params_for_runs[0])]\n",
    "        \n",
    "        ga_all_solutions_config = [res[0] for res in ga_results_parallel if res is not None and res[0] is not None]\n",
    "        ga_all_fitness_values_config = [res[1] for res in ga_results_parallel if res is not None]\n",
    "        ga_all_exec_times_config = [res[2] for res in ga_results_parallel if res is not None]\n",
    "        ga_all_histories_config = [res[3] for res in ga_results_parallel if res is not None]\n",
    "\n",
    "        best_ga_fitness_config = float(\"inf\")\n",
    "        best_ga_solution_config = None\n",
    "        best_ga_history_config = []\n",
    "        if ga_all_solutions_config:\n",
    "            for i, fit_val in enumerate(ga_all_fitness_values_config):\n",
    "                if not np.isnan(fit_val) and fit_val < best_ga_fitness_config:\n",
    "                    if i < len(ga_all_solutions_config) and ga_all_solutions_config[i] is not None and \\\n",
    "                       i < len(ga_all_histories_config) and ga_all_histories_config[i] is not None:\n",
    "                        best_ga_fitness_config = fit_val\n",
    "                        best_ga_solution_config = ga_all_solutions_config[i]\n",
    "                        best_ga_history_config = ga_all_histories_config[i]\n",
    "\n",
    "        ga_mean_fitness_config = np.nanmean([f for f in ga_all_fitness_values_config if not np.isnan(f)]) if any(not np.isnan(f) for f in ga_all_fitness_values_config) else float(\"nan\")\n",
    "        ga_std_fitness_config = np.nanstd([f for f in ga_all_fitness_values_config if not np.isnan(f)]) if any(not np.isnan(f) for f in ga_all_fitness_values_config) else float(\"nan\")\n",
    "        ga_mean_exec_time_config = np.nanmean([t for t in ga_all_exec_times_config if not np.isnan(t)]) if any(not np.isnan(t) for t in ga_all_exec_times_config) else float(\"nan\")\n",
    "\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        # Indentation of this print was one level deeper in MP ref, adjusting to be consistent with HC/SA section summaries\n",
    "        print(f\"  [{timestamp}] GA Config {config_name} ({NUM_RUNS} runs) - Mean Fitness: {ga_mean_fitness_config:.4f}, Std Dev Fitness: {ga_std_fitness_config:.4f}, Mean Exec Time: {ga_mean_exec_time_config:.2f}s\")\n",
    "        if best_ga_solution_config:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"    [{timestamp}] GA Config {config_name} - Overall Best Fitness: {best_ga_fitness_config:.4f}\")\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": f\"GA: {config_name} (MP-{NUM_RUNS} runs)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": best_ga_fitness_config,\n",
    "                \"Mutation Op\": ga_params_dict[\"mutation_op\"].__name__,\n",
    "                \"Crossover Op\": ga_params_dict[\"crossover_op\"].__name__,\n",
    "                \"Selection Op\": ga_params_dict[\"selection_op\"].__name__\n",
    "            })\n",
    "            if best_ga_history_config and isinstance(best_ga_history_config[0], (int, float, np.number)):\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(best_ga_history_config, marker=\"o\", linestyle=\"-\", markersize=4) # markersize from MP ref\n",
    "                plt.title(f\"GA Convergence: {config_name} (Best of {NUM_RUNS} MP Runs)\")\n",
    "                plt.xlabel(\"Generation\")\n",
    "                plt.ylabel(\"Best Fitness in Population\")\n",
    "                plt.grid(True)\n",
    "                plt.savefig(os.path.join(IMAGES_MP_DIR, f\"ga_convergence_{config_name}_mp_{NUM_RUNS}runs.png\"))\n",
    "                timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(f\"    [{timestamp}] Saved GA convergence plot to {IMAGES_MP_DIR}/ga_convergence_{config_name}_mp_{NUM_RUNS}runs.png\")\n",
    "                plt.close()\n",
    "            elif best_ga_history_config: # If history exists but not plottable as numbers\n",
    "                 timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                 print(f\"    [{timestamp}] GA Config {config_name} - Fitness history for best run is not in the expected format for plotting (e.g. list of numbers). Type: {type(best_ga_history_config[0])}\")\n",
    "            else: # No history or empty history\n",
    "                timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(f\"    [{timestamp}] No valid fitness history to plot for GA config {config_name}.\")\n",
    "        else:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"    [{timestamp}] GA Config {config_name} did not find any valid solution across all runs that produced a best overall.\")\n",
    "            # Append with NaN for best fitness if no solution found\n",
    "            all_results_summary.append({\n",
    "                \"Algorithm\": f\"GA: {config_name} (MP-{NUM_RUNS} runs)\",\n",
    "                \"Mean Fitness\": ga_mean_fitness_config,\n",
    "                \"Std Dev Fitness\": ga_std_fitness_config,\n",
    "                \"Mean Exec Time (s)\": ga_mean_exec_time_config,\n",
    "                \"Overall Best Fitness\": float(\"nan\"),\n",
    "                \"Mutation Op\": ga_params_dict[\"mutation_op\"].__name__,\n",
    "                \"Crossover Op\": ga_params_dict[\"crossover_op\"].__name__,\n",
    "                \"Selection Op\": ga_params_dict[\"selection_op\"].__name__\n",
    "            })\n",
    "        config_end_time = time.time()\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"  [{timestamp}] GA Configuration {config_name} section took {config_end_time - config_start_time:.2f} seconds.\")\n",
    "\n",
    "    ga_section_end_time = time.time()\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Genetic Algorithms section took {ga_section_end_time - ga_section_start_time:.2f} seconds (wall time for parallel execution).\")\n",
    "\n",
    "    # --- 4. Comparative Plots and Summary CSV --- \n",
    "    if all_results_summary:\n",
    "        results_df = pd.DataFrame(all_results_summary)\n",
    "        \n",
    "        # Comparative Execution Times Plot\n",
    "        plt.figure(figsize=(14, 8)) # Adjusted figure size for better readability\n",
    "        plot_df_times = results_df.dropna(subset=[\"Mean Exec Time (s)\"])\n",
    "        if not plot_df_times.empty:\n",
    "            alg_names_times = [name.replace(f\" (MP-{NUM_RUNS} runs)\", \"\") for name in plot_df_times[\"Algorithm\"]]\n",
    "            bars = plt.bar(alg_names_times, plot_df_times[\"Mean Exec Time (s)\"], color=plt.cm.viridis(np.linspace(0, 1, len(plot_df_times))))\n",
    "            plt.xlabel(\"Algorithm / Configuration\")\n",
    "            plt.ylabel(\"Mean Execution Time per Run (s)\")\n",
    "            plt.title(f\"Comparative Mean Execution Times ({NUM_RUNS} MP Runs)\")\n",
    "            plt.xticks(rotation=60, ha=\"right\") # Rotate labels for better fit\n",
    "            plt.tight_layout() # Adjust layout\n",
    "            for bar in bars:\n",
    "                yval = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.05 * yval, f\"{yval:.2f}s\", ha=\"center\", va=\"bottom\")\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"comparative_times_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] Saved comparative execution times plot to {IMAGES_MP_DIR}/comparative_times_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] No valid data for comparative execution times plot after dropping NaNs.\")\n",
    "\n",
    "        # Comparative Best Fitness Plot\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plot_df_fitness = results_df.dropna(subset=[\"Overall Best Fitness\"])\n",
    "        if not plot_df_fitness.empty:\n",
    "            alg_names_fitness = [name.replace(f\" (MP-{NUM_RUNS} runs)\", \"\") for name in plot_df_fitness[\"Algorithm\"]]\n",
    "            bars = plt.bar(alg_names_fitness, plot_df_fitness[\"Overall Best Fitness\"], color=plt.cm.plasma(np.linspace(0, 1, len(plot_df_fitness))))\n",
    "            plt.xlabel(\"Algorithm / Configuration\")\n",
    "            plt.ylabel(\"Overall Best Fitness Achieved\")\n",
    "            plt.title(f\"Comparative Overall Best Fitness ({NUM_RUNS} MP Runs)\")\n",
    "            plt.xticks(rotation=60, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            for bar in bars:\n",
    "                yval = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.05 * yval, f\"{yval:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "            plt.savefig(os.path.join(IMAGES_MP_DIR, f\"comparative_fitness_mp_{NUM_RUNS}runs.png\"))\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] Saved comparative best fitness plot to {IMAGES_MP_DIR}/comparative_fitness_mp_{NUM_RUNS}runs.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{timestamp}] No valid data for comparative best fitness plot after dropping NaNs.\")\n",
    "\n",
    "        # Save Summary CSV\n",
    "        summary_file_path = os.path.join(IMAGES_MP_DIR, f\"all_algorithms_summary_mp_{NUM_RUNS}runs.csv\")\n",
    "        results_df.to_csv(summary_file_path, index=False)\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] Saved all algorithms summary to {summary_file_path}\")\n",
    "    else:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] No results to plot or save in summary CSV.\")\n",
    "\n",
    "    script_total_end_time = time.time()\n",
    "    total_script_duration = script_total_end_time - script_total_start_time\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\n[{timestamp}] Multiprocessing Script execution finished.\") # Added newline for separation\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] Total script execution time: {total_script_duration:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b681f",
   "metadata": {},
   "source": [
    "## Script Execution Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb94d4",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.freeze_support()  # Good practice for multiprocessing, esp. on Windows\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}